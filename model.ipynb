{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载预处理后的数据\n",
    "title2int, title_count, title_set, genres2int, genres_map, features_pd, targets_pd, features, targets_values, ratings_df, users_df, movies_df, data = pickle.load(open('./data/preprocess.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...</td>\n",
       "      <td>[1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "      <td>[3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...</td>\n",
       "      <td>[1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>32793</td>\n",
       "      <td>[3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...</td>\n",
       "      <td>[1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1193</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>22903</td>\n",
       "      <td>[3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...</td>\n",
       "      <td>[1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1193</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>95350</td>\n",
       "      <td>[3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...</td>\n",
       "      <td>[1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  gender  age  occupation zip_code  \\\n",
       "0        1      1193       1    0          10    48067   \n",
       "1        2      1193       0    5          16    70072   \n",
       "2       12      1193       0    6          12    32793   \n",
       "3       15      1193       0    6           7    22903   \n",
       "4       17      1193       0    3           1    95350   \n",
       "\n",
       "                                               title  \\\n",
       "0  [3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...   \n",
       "1  [3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...   \n",
       "2  [3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...   \n",
       "3  [3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...   \n",
       "4  [3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...   \n",
       "\n",
       "                                              genres  \n",
       "0  [1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "1  [1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "2  [1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "3  [1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "4  [1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  "
      ]
     },
     "execution_count": 1112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户ID个数:6041\n",
      "性别个数:2\n",
      "年龄类别个数:7\n",
      "职业个数:21\n",
      "电影ID个数:3953\n",
      "电影类型个数:19\n",
      "电影名单词个数:5217\n"
     ]
    }
   ],
   "source": [
    "#嵌入矩阵的维度\n",
    "embed_dim = 64\n",
    "#用户ID个数\n",
    "uid_num = max(features.take(0,1)) + 1 # 6040\n",
    "#性别个数\n",
    "gender_num = max(features.take(2,1)) + 1 # 1 + 1 = 2\n",
    "#年龄类别个数\n",
    "age_num = max(features.take(3,1)) + 1 # 6 + 1 = 7\n",
    "#职业个数\n",
    "job_num = max(features.take(4,1)) + 1# 20 + 1 = 21\n",
    "\n",
    "#电影ID个数\n",
    "mid_num = max(features.take(1,1)) + 1 # 3952\n",
    "#电影类型个数\n",
    "movie_category_num = max(genres2int.values()) + 1 # 18 + 1 = 19\n",
    "# 因为这些都是从0开始计数的，因此需要加1\n",
    "#电影名单词个数\n",
    "movie_title_num = len(title_set) # 5216\n",
    "\n",
    "\n",
    "\n",
    "print(f\"用户ID个数:{uid_num}\")\n",
    "print(f\"性别个数:{gender_num}\")\n",
    "print(f\"年龄类别个数:{age_num}\")\n",
    "print(f\"职业个数:{job_num}\")\n",
    "print(f\"电影ID个数:{mid_num}\")\n",
    "print(f\"电影类型个数:{movie_category_num}\")\n",
    "print(f\"电影名单词个数:{movie_title_num}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对电影类型的embedding向量做sum操作\n",
    "combiner=\"sum\"\n",
    "\n",
    "# 电影名长度\n",
    "sentence_size=title_count # 15\n",
    "# 文本卷积滑动窗口\n",
    "window_sizes={2,3,4,5}\n",
    "# 文本卷积核数量\n",
    "filter_num=8\n",
    "\n",
    "# 电影ID转下标的字典\n",
    "movieid2idx={val[0]: i for i, val in enumerate(movies_df.values)}\n",
    "# 这里面的i是movies_df的索引，val是其value值，也就是movie_id, title, genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "num_epochs=5\n",
    "batch_size=256\n",
    "\n",
    "dropout_keep_prob=0.5\n",
    "learning_rate=0.0001\n",
    "show_every_n_batches=20\n",
    "\n",
    "save_dir='./save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding(uid, user_gender, user_age, user_job, uid_num, gender_num, age_num, job_num, embed_dim):\n",
    "    # 用户ID embedding\n",
    "    uid_embedding=nn.Embedding(uid_num, embed_dim) # 输入特征维度为uid_num，输出特征维度为embed_dim\n",
    "    uid_embed_layer=uid_embedding(uid)\n",
    "\n",
    "    # 性别embedding\n",
    "    gender_embedding=nn.Embedding(gender_num, embed_dim//2)\n",
    "    gender_embed_layer=gender_embedding(user_gender)\n",
    "\n",
    "    # 年龄embedding\n",
    "    age_embedding=nn.Embedding(age_num, embed_dim//2)\n",
    "    age_embed_layer=age_embedding(user_age)\n",
    "\n",
    "    # 职业embedding\n",
    "    job_embedding=nn.Embedding(job_num, embed_dim//2)\n",
    "    job_embed_layer=job_embedding(user_job)\n",
    "\n",
    "    return uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_feature_layer(uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer):\n",
    "    # 定义激活函数\n",
    "    relu=nn.ReLU()\n",
    "    tanh=nn.Tanh()\n",
    "\n",
    "    # 第一层全连接\n",
    "    uid_fc_layer=nn.Linear(uid_embed_layer.size(-1), embed_dim)\n",
    "\n",
    "    gender_fc_layer=nn.Linear(gender_embed_layer.size(-1), embed_dim)\n",
    "    age_fc_layer=nn.Linear(age_embed_layer.size(-1), embed_dim)\n",
    "    job_fc_layer=nn.Linear(job_embed_layer.size(-1), embed_dim)\n",
    "\n",
    "    # 激活函数层\n",
    "    uid_fc_output=relu(uid_fc_layer(uid_embed_layer))\n",
    "    gender_fc_output=relu(gender_fc_layer(gender_embed_layer))\n",
    "    age_fc_output=relu(age_fc_layer(age_embed_layer))\n",
    "    job_fc_output=relu(job_fc_layer(job_embed_layer))\n",
    "\n",
    "    # 拼接\n",
    "    user_combine_layer=torch.cat([uid_fc_output, gender_fc_output, age_fc_output, job_fc_output], dim=-1)\n",
    "\n",
    "    # 第二层全连接层\n",
    "    user_combine_fc=nn.Linear(user_combine_layer.size(-1),200)\n",
    "    user_combine_layer=tanh(user_combine_fc(user_combine_layer))\n",
    "\n",
    "    # 扁平化\n",
    "    user_combine_layer_flat=user_combine_layer.view(-1, 200)\n",
    "\n",
    "    return user_combine_layer, user_combine_layer_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义movie id的嵌入矩阵\n",
    "def get_movie_id_embed_layer(movie_id, mid_num, embed_dim):\n",
    "    # 嵌入层\n",
    "    movie_id_embedding=nn.Embedding(mid_num, embed_dim)\n",
    "    # 获取embedding向量\n",
    "    movie_id_embed_layer=movie_id_embedding(movie_id)\n",
    "    return movie_id_embed_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对电影类型的多个embedding向量做加权和\n",
    "def get_movie_categories_layers(movie_categories, movie_category_num, embed_dim):\n",
    "    # 创建嵌入层\n",
    "    movie_categories_embedding=nn.Embedding(movie_category_num, embed_dim)\n",
    "    # 获取embedding向量\n",
    "    movie_categories_embed_layer=movie_categories_embedding(movie_categories)\n",
    "\n",
    "    # 根据combiner参数进行处理\n",
    "    if combiner=='sum':\n",
    "        movie_categories_embed_layer=torch.sum(movie_categories_embed_layer, dim=1, keepdim=True)\n",
    "    return movie_categories_embed_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 电影标题的文本卷积网络实现\n",
    "def get_movie_cnn_layer(movie_titles, embed_dim, window_sizes, filter_num, sentence_size, dropout_keep_prob):\n",
    "    # 从嵌入矩阵中得到电影名对应的各个单词的嵌入向量\n",
    "    # 1. 创建embedding矩阵，用于将电影标题中的单词索引转换为embedding向量\n",
    "    movie_title_embedding=nn.Embedding(movie_title_num, embed_dim)\n",
    "    # 2. 获取电影标题对应的embedding向量\n",
    "    movie_title_embed_layer=movie_title_embedding(movie_titles) # [256, 15, 64]\n",
    "    # print(f\"movie_title_embed_layer shape:{movie_title_embed_layer.shape}\")\n",
    "    # 3. 在最后一个维度上增加一个维度，以满足卷积层的输入要求\n",
    "    movie_title_embed_layer_expand=movie_title_embed_layer.unsqueeze(1) # [256, 1, 15, 64]\n",
    "    # print(f\"movie_title_embed_layer_expand shape:{movie_title_embed_layer_expand.shape}\")\n",
    "\n",
    "    # 对文本嵌入层使用不同尺寸的卷积核做卷积和最大池化\n",
    "    pool_layer_lst=[]\n",
    "    for window_size in window_sizes:\n",
    "        # 创建卷积层\n",
    "        # out_channels（输出通道数）:8\n",
    "        # in_channels（输入通道数）:1\n",
    "        # kernel_height（卷积核高度）:2\n",
    "        # kernel_width（卷积核宽度）:32\n",
    "        conv=nn.Conv2d(1, filter_num, (window_size, embed_dim))\n",
    "        filter_weights=conv.weight\n",
    "        filter_bias=conv.bias \n",
    "\n",
    "        # 卷积操作\n",
    "        conv_layer=conv(movie_title_embed_layer_expand)\n",
    "        relu_layer=F.relu(conv_layer+filter_bias)\n",
    "\n",
    "        # 最大池化操作\n",
    "        maxpool_layer=F.max_pool2d(relu_layer, (relu_layer.size(2), relu_layer.size(3))) # [256, 8, 1, 8]\n",
    "        # 要把maxpool_layer变成[256, 8, 1, 1]\n",
    "        # print(f\"{maxpool_layer.shape}\")\n",
    "        pool_layer_lst.append(maxpool_layer) # [256, 8, 1, 8] 因为有4个window_size\n",
    "\n",
    "\n",
    "\n",
    "    pool_layer=torch.cat(pool_layer_lst, dim=-1) # [256, 32, 1, 8]\n",
    "    # print(f\"pool_layer shape:{pool_layer.shape}\") # [256, 8, 1, 4]\n",
    "    # print(f\"{pool_layer.shape}\")\n",
    "    max_num=len(window_sizes)*filter_num # 32\n",
    "    # 将拼接后的结果进行扁平化处理\n",
    "    batch_size = movie_titles.size(0)  # 256  size(0)为256 size(1)为15\n",
    "    # 这里会出现报错，因为[256, 32, 1, 8]和[256, 1, 32]的维度对不上\n",
    "    pool_layer_flat=pool_layer.view(batch_size, 1, max_num) # [256, 1, 32]\n",
    "    # print(f\"pool_layer_flat shape:{pool_layer_flat.shape}\")\n",
    "\n",
    "    # 创建dropout层\n",
    "    dropout=nn.Dropout(1-dropout_keep_prob)\n",
    "    # 应用dropout操作\n",
    "    dropout_layer=dropout(pool_layer_flat) # [256, 1, 32]\n",
    "    # print(f\"dropout_layer shape:{dropout_layer.shape}\")\n",
    "\n",
    "    return pool_layer_flat, dropout_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将movie的各个层一起做全连接\n",
    "def get_movie_feature_layer(movie_id_embed_layer, movie_categories_embed_layer, dropout_layer):\n",
    "    relu = nn.ReLU()\n",
    "    tanh = nn.Tanh()\n",
    "    # 处理dropout_layer的维度\n",
    "    # 第一层全连接\n",
    "    movie_id_fc = nn.Linear(movie_id_embed_layer.size(-1), embed_dim)\n",
    "    movie_categories_fc = nn.Linear(movie_categories_embed_layer.squeeze(1).size(-1), embed_dim)\n",
    "\n",
    "    movie_id_fc_layer = relu(movie_id_fc(movie_id_embed_layer)) # [256, 64]\n",
    "    \n",
    "    # squeeze用于移除所有维度大小为1的维度\n",
    "    movie_categories_fc_layer = relu(movie_categories_fc(movie_categories_embed_layer.squeeze())) # [256, 64]\n",
    "    # 调整dropout_layer的维度，从[256,1,32]变为[256,32]\n",
    "    dropout_layer = dropout_layer.squeeze(1)\n",
    "    # 检查 dropout_layer 的维度和大小\n",
    "    if dropout_layer.size(0) != movie_id_embed_layer.size(0):\n",
    "        raise ValueError(f\"dropout_layer 的第一维大小 {dropout_layer.size(0)} 与 movie_id_embed_layer 的第一维大小 {movie_id_embed_layer.size(0)} 不一致。\")\n",
    "\n",
    "    # 拼接\n",
    "    movie_combine_layer = torch.cat([movie_id_fc_layer, movie_categories_fc_layer, dropout_layer], dim=-1)\n",
    "\n",
    "    # 第二层全连接\n",
    "    movie_combine_fc = nn.Linear(movie_combine_layer.size(-1), 200)\n",
    "    movie_combine_layer = tanh(movie_combine_fc(movie_combine_layer))\n",
    "\n",
    "    # 扁平化\n",
    "    movie_combine_layer_flat = movie_combine_layer.view(-1, 200)\n",
    "\n",
    "    return movie_combine_layer, movie_combine_layer_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_targets, test_targets = train_test_split(features,  targets_values, test_size=0.2,\n",
    "                                                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        uid = torch.tensor(self.features[idx][0])\n",
    "        movie_id = torch.tensor(self.features[idx][1])\n",
    "        user_gender = torch.tensor(self.features[idx][2])\n",
    "        user_age = torch.tensor(self.features[idx][3])\n",
    "        user_job = torch.tensor(self.features[idx][4])\n",
    "        movie_titles = torch.tensor(self.features[idx][6])\n",
    "        movie_categories=torch.tensor(self.features[idx][7])\n",
    "        targets = torch.tensor(self.targets[idx]).float()\n",
    "        return uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MovieDataset(train_features, train_targets)\n",
    "test_dataset = MovieDataset(test_features, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieRecommendationModel(nn.Module):\n",
    "    def __init__(self, uid_num, gender_num, age_num, job_num, embed_dim, mid_num, movie_category_num, movie_title_num):\n",
    "        super(MovieRecommendationModel, self).__init__()\n",
    "        # 用户嵌入层\n",
    "        self.uid_embedding = nn.Embedding(uid_num, embed_dim)\n",
    "        self.gender_embedding = nn.Embedding(gender_num, embed_dim)\n",
    "        self.age_embedding = nn.Embedding(age_num, embed_dim)\n",
    "        self.job_embedding = nn.Embedding(job_num, embed_dim)\n",
    "        # 电影嵌入层\n",
    "        self.movie_id_embedding = nn.Embedding(mid_num, embed_dim)\n",
    "        self.movie_categories_embedding = nn.Embedding(movie_category_num, embed_dim)\n",
    "        self.movie_title_embedding = nn.Embedding(movie_title_num, embed_dim)\n",
    "\n",
    "    def forward(self, uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles):\n",
    "        # 获取用户嵌入向量\n",
    "        uid_embed_layer = self.uid_embedding(uid)\n",
    "        gender_embed_layer = self.gender_embedding(user_gender)\n",
    "        age_embed_layer = self.age_embedding(user_age)\n",
    "        job_embed_layer = self.job_embedding(user_job)\n",
    "\n",
    "        # 获取电影ID的嵌入向量\n",
    "        movie_id_embed_layer = self.movie_id_embedding(movie_id)\n",
    "\n",
    "        # 得到用户特征\n",
    "        user_combine_layer, user_combine_layer_flat = get_user_feature_layer(uid_embed_layer, gender_embed_layer,\n",
    "                                                                             age_embed_layer, job_embed_layer)\n",
    "        # 获取电影类型的嵌入向量\n",
    "        movie_categories_embed_layer = self.movie_categories_embedding(movie_categories)\n",
    "\n",
    "        movie_categories_embed_layer=torch.sum(movie_categories_embed_layer, dim=1, keepdim=True)\n",
    "\n",
    "        # 获取电影名的特征向量\n",
    "        movie_title_embed_layer = self.movie_title_embedding(movie_titles)\n",
    "        movie_title_embed_layer_expand = movie_title_embed_layer.unsqueeze(1)\n",
    "        pool_layer_flat, dropout_layer = get_movie_cnn_layer(movie_titles, embed_dim, window_sizes,\n",
    "                                                             filter_num, sentence_size, dropout_keep_prob)\n",
    "\n",
    "        # 得到电影特征\n",
    "        movie_combine_layer, movie_combine_layer_flat = get_movie_feature_layer(movie_id_embed_layer,\n",
    "                                                                                movie_categories_embed_layer,\n",
    "                                                                                dropout_layer)\n",
    "\n",
    "        # 计算预测评分\n",
    "        inference = torch.sum(user_combine_layer_flat * movie_combine_layer_flat, dim=1, keepdim=True)\n",
    "        return inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MovieRecommendationModel(uid_num, gender_num, age_num, job_num, embed_dim, mid_num, movie_category_num, movie_title_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uid max: 6025, min: 23\n",
      "user_gender max: 1, min: 0\n",
      "user_age max: 6, min: 0\n",
      "user_job max: 20, min: 0\n",
      "movie_id max: 3910, min: 6\n",
      "movie_categories max: 18, min: 0\n",
      "movie_titles max: 5187, min: 10\n",
      "uid contains out of range values: False\n",
      "user_gender contains out of range values: False\n",
      "user_age contains out of range values: False\n",
      "user_job contains out of range values: False\n",
      "movie_id contains out of range values: False\n",
      "movie_categories contains out of range values: False\n",
      "movie_titles contains out of range values: False\n"
     ]
    }
   ],
   "source": [
    "def check_embedding_inputs(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles):\n",
    "    # 打印最大值和最小值\n",
    "    print(f\"uid max: {uid.max()}, min: {uid.min()}\")\n",
    "    print(f\"user_gender max: {user_gender.max()}, min: {user_gender.min()}\")\n",
    "    print(f\"user_age max: {user_age.max()}, min: {user_age.min()}\")\n",
    "    print(f\"user_job max: {user_job.max()}, min: {user_job.min()}\")\n",
    "    print(f\"movie_id max: {movie_id.max()}, min: {movie_id.min()}\")\n",
    "    print(f\"movie_categories max: {movie_categories.max()}, min: {movie_categories.min()}\")\n",
    "    print(f\"movie_titles max: {movie_titles.max()}, min: {movie_titles.min()}\")\n",
    "\n",
    "    # 检查是否超出范围\n",
    "    print(f\"uid contains out of range values: {torch.any(uid >= uid_num)}\")\n",
    "    print(f\"user_gender contains out of range values: {torch.any(user_gender >= gender_num)}\")\n",
    "    print(f\"user_age contains out of range values: {torch.any(user_age >= age_num)}\")\n",
    "    print(f\"user_job contains out of range values: {torch.any(user_job >= job_num)}\")\n",
    "    print(f\"movie_id contains out of range values: {torch.any(movie_id >= mid_num)}\")\n",
    "    print(f\"movie_categories contains out of range values: {torch.any(movie_categories >= movie_category_num)}\")\n",
    "    print(f\"movie_titles contains out of range values: {torch.any(movie_titles >= movie_title_num)}\")\n",
    "\n",
    "# 在 DataLoader 中调用检查函数\n",
    "# user_gender和movie_categories有问题\n",
    "for batch in train_loader:\n",
    "    uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, target = batch\n",
    "    check_embedding_inputs(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...</td>\n",
       "      <td>[1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "      <td>[3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...</td>\n",
       "      <td>[1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>32793</td>\n",
       "      <td>[3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...</td>\n",
       "      <td>[1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>22903</td>\n",
       "      <td>[3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...</td>\n",
       "      <td>[1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>95350</td>\n",
       "      <td>[3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...</td>\n",
       "      <td>[1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  gender  age  occupation zip_code  \\\n",
       "0        1      1193       5       1    0          10    48067   \n",
       "1        2      1193       5       0    5          16    70072   \n",
       "2       12      1193       4       0    6          12    32793   \n",
       "3       15      1193       4       0    6           7    22903   \n",
       "4       17      1193       5       0    3           1    95350   \n",
       "\n",
       "                                               title  \\\n",
       "0  [3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...   \n",
       "1  [3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...   \n",
       "2  [3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...   \n",
       "3  [3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...   \n",
       "4  [3121, 4870, 1869, 4010, 2380, 3321, 4682, 468...   \n",
       "\n",
       "                                              genres  \n",
       "0  [1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "1  [1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "2  [1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "3  [1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "4  [1, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  "
      ]
     },
     "execution_count": 1130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linjiaxi/Anaconda/anaconda3/envs/news_recommendation_env/lib/python3.8/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([256, 1, 1])) that is different to the input size (torch.Size([256, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Batch [0/3126], Loss: 8.6023\n",
      "Epoch [1/5], Batch [20/3126], Loss: 53.1054\n",
      "Epoch [1/5], Batch [40/3126], Loss: 36.9598\n",
      "Epoch [1/5], Batch [60/3126], Loss: 27.1443\n",
      "Epoch [1/5], Batch [80/3126], Loss: 15.2569\n",
      "Epoch [1/5], Batch [100/3126], Loss: 30.3278\n",
      "Epoch [1/5], Batch [120/3126], Loss: 5.3880\n",
      "Epoch [1/5], Batch [140/3126], Loss: 10.8339\n",
      "Epoch [1/5], Batch [160/3126], Loss: 13.7394\n",
      "Epoch [1/5], Batch [180/3126], Loss: 9.3967\n",
      "Epoch [1/5], Batch [200/3126], Loss: 8.3369\n",
      "Epoch [1/5], Batch [220/3126], Loss: 3.5639\n",
      "Epoch [1/5], Batch [240/3126], Loss: 56.9567\n",
      "Epoch [1/5], Batch [260/3126], Loss: 16.8510\n",
      "Epoch [1/5], Batch [280/3126], Loss: 29.6990\n",
      "Epoch [1/5], Batch [300/3126], Loss: 10.8068\n",
      "Epoch [1/5], Batch [320/3126], Loss: 3.8089\n",
      "Epoch [1/5], Batch [340/3126], Loss: 12.1822\n",
      "Epoch [1/5], Batch [360/3126], Loss: 14.3259\n",
      "Epoch [1/5], Batch [380/3126], Loss: 24.8976\n",
      "Epoch [1/5], Batch [400/3126], Loss: 29.0486\n",
      "Epoch [1/5], Batch [420/3126], Loss: 18.9179\n",
      "Epoch [1/5], Batch [440/3126], Loss: 22.6809\n",
      "Epoch [1/5], Batch [460/3126], Loss: 11.7170\n",
      "Epoch [1/5], Batch [480/3126], Loss: 20.2057\n",
      "Epoch [1/5], Batch [500/3126], Loss: 23.3065\n",
      "Epoch [1/5], Batch [520/3126], Loss: 11.1966\n",
      "Epoch [1/5], Batch [540/3126], Loss: 13.0403\n",
      "Epoch [1/5], Batch [560/3126], Loss: 4.9376\n",
      "Epoch [1/5], Batch [580/3126], Loss: 37.4429\n",
      "Epoch [1/5], Batch [600/3126], Loss: 16.1871\n",
      "Epoch [1/5], Batch [620/3126], Loss: 32.8323\n",
      "Epoch [1/5], Batch [640/3126], Loss: 11.1136\n",
      "Epoch [1/5], Batch [660/3126], Loss: 37.9398\n",
      "Epoch [1/5], Batch [680/3126], Loss: 8.3586\n",
      "Epoch [1/5], Batch [700/3126], Loss: 30.2421\n",
      "Epoch [1/5], Batch [720/3126], Loss: 6.3866\n",
      "Epoch [1/5], Batch [740/3126], Loss: 15.6798\n",
      "Epoch [1/5], Batch [760/3126], Loss: 10.0731\n",
      "Epoch [1/5], Batch [780/3126], Loss: 47.0033\n",
      "Epoch [1/5], Batch [800/3126], Loss: 16.4595\n",
      "Epoch [1/5], Batch [820/3126], Loss: 26.9197\n",
      "Epoch [1/5], Batch [840/3126], Loss: 18.4040\n",
      "Epoch [1/5], Batch [860/3126], Loss: 30.2554\n",
      "Epoch [1/5], Batch [880/3126], Loss: 32.6609\n",
      "Epoch [1/5], Batch [900/3126], Loss: 42.2119\n",
      "Epoch [1/5], Batch [920/3126], Loss: 11.3053\n",
      "Epoch [1/5], Batch [940/3126], Loss: 16.9631\n",
      "Epoch [1/5], Batch [960/3126], Loss: 13.2315\n",
      "Epoch [1/5], Batch [980/3126], Loss: 14.5591\n",
      "Epoch [1/5], Batch [1000/3126], Loss: 8.8623\n",
      "Epoch [1/5], Batch [1020/3126], Loss: 44.8555\n",
      "Epoch [1/5], Batch [1040/3126], Loss: 36.5035\n",
      "Epoch [1/5], Batch [1060/3126], Loss: 10.9444\n",
      "Epoch [1/5], Batch [1080/3126], Loss: 23.7883\n",
      "Epoch [1/5], Batch [1100/3126], Loss: 8.4704\n",
      "Epoch [1/5], Batch [1120/3126], Loss: 10.5414\n",
      "Epoch [1/5], Batch [1140/3126], Loss: 12.3587\n",
      "Epoch [1/5], Batch [1160/3126], Loss: 18.1527\n",
      "Epoch [1/5], Batch [1180/3126], Loss: 8.9715\n",
      "Epoch [1/5], Batch [1200/3126], Loss: 7.2327\n",
      "Epoch [1/5], Batch [1220/3126], Loss: 27.2063\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1131], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m output \u001b[38;5;241m=\u001b[39m model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles)\n\u001b[1;32m      7\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 8\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader) \u001b[38;5;241m+\u001b[39m batch_i) \u001b[38;5;241m%\u001b[39m show_every_n_batches \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/news_recommendation_env/lib/python3.8/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Anaconda/anaconda3/envs/news_recommendation_env/lib/python3.8/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_i, (uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, target) in enumerate(\n",
    "                train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles)\n",
    "            loss = criterion(output, target.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (epoch * len(train_loader) + batch_i) % show_every_n_batches == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "                      f'Batch [{batch_i}/{len(train_loader)}], '\n",
    "                      f'Loss: {loss.item():.4f}')\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_i, (uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, target) in enumerate(\n",
    "                    test_loader):\n",
    "                output = model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles)\n",
    "                loss = criterion(output, target.unsqueeze(1))\n",
    "                test_loss += loss.item()\n",
    "            test_loss /= len(test_loader)\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], '\n",
    "                  f'Test Loss: {test_loss:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "news_recommendation_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
