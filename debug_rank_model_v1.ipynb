{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from typing import List, Tuple\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINModel(nn.Module):\n",
    "    def __init__(self, uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num, max_hist_len, embedding_dim=16, attention_units=32):\n",
    "        \"\"\"初始化DIN模型\"\"\"\n",
    "        super(DINModel, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # 用户特征嵌入层\n",
    "        self.uid_embedding = nn.Embedding(uid_num, embedding_dim)\n",
    "        self.gender_embedding = nn.Embedding(gender_num, embedding_dim//2)\n",
    "        self.age_embedding = nn.Embedding(age_num, embedding_dim//2)\n",
    "        self.job_embedding = nn.Embedding(job_num, embedding_dim//2)\n",
    "\n",
    "        # 电影特征嵌入层\n",
    "        self.movie_id_embedding = nn.Embedding(mid_num, embedding_dim)\n",
    "        self.movie_categories_embedding = nn.Embedding(movie_category_num, embedding_dim)\n",
    "        \n",
    "        self.movie_title_embedding = nn.Embedding(movie_title_num, embedding_dim//2)\n",
    "\n",
    "        # 历史电影特征嵌入层\n",
    "        self.history_movie_embedding = nn.Embedding(max_hist_len, embedding_dim)\n",
    "        # 注意力层\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, attention_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(attention_units, attention_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(attention_units, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # 预测层\n",
    "        self.prediction = nn.Sequential(\n",
    "            nn.Linear(57, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        # print(\"预测层维度:\", self.prediction)\n",
    "        \n",
    "    def forward(self, uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, history_movie_ids):\n",
    "        \"\"\"前向传播\n",
    "        Args:\n",
    "            uid: 用户ID [batch_size]\n",
    "            user_gender: 用户性别 [batch_size]\n",
    "            user_age: 用户年龄 [batch_size]\n",
    "            user_job: 用户职业 [batch_size]\n",
    "            movie_id: 候选电影ID [batch_size]\n",
    "            movie_categories: 候选电影类别 [batch_size]\n",
    "            movie_titles: 候选电影标题 [batch_size]\n",
    "            history_movie_ids: 历史交互电影ID [batch_size, hist_len]\n",
    "        \"\"\"\n",
    "        # 嵌入用户特征\n",
    "        uid_embed = self.uid_embedding(uid) # torch.size([32, 16])\n",
    "        # print(\"用户ID维度:\", uid_embed.size())\n",
    "        gender_embed = self.gender_embedding(user_gender) # torch.size([32, 8])\n",
    "        # print(\"用户性别维度:\", gender_embed.size())\n",
    "        age_embed = self.age_embedding(user_age) # torch.size([32, 8])\n",
    "        # print(\"年龄维度:\", age_embed.size())\n",
    "        job_embed = self.job_embedding(user_job) # torch.size([32, 8])\n",
    "        # print(\"用户职业维度:\", job_embed.size())\n",
    "        \n",
    "        # 嵌入候选电影特征\n",
    "        movie_id_embed = self.movie_id_embedding(movie_id) # torch.size([32, 16])\n",
    "        # print(\"电影ID维度:\", movie_id_embed.size())\n",
    "        movie_categories_embed = self.movie_categories_embedding(movie_categories) # torch.size([32, 18, 16])\n",
    "        # print(\"电影类型维度:\", movie_categories_embed.size())\n",
    "        movie_titles_embed = self.movie_title_embedding(movie_titles) # torch.size([32, 15, 8])\n",
    "        # print(\"电影标题维度:\", movie_titles_embed.size())\n",
    "        # print(\"电影标题的类型:\", movie_titles_embed.dtype)\n",
    "        # 嵌入历史电影ID特征\n",
    "        # print(\"历史电影ID的类型:\", history_movie_ids.dtype)\n",
    "        hist_movie_embed = self.movie_id_embedding(history_movie_ids) # torch.size([32, 16])\n",
    "        # print('历史电影ID维度:', hist_movie_embed.size())\n",
    "\n",
    "        \n",
    "        # 注意力机制处理历史交互\n",
    "        attention_input = torch.cat([\n",
    "            movie_id_embed,\n",
    "            hist_movie_embed\n",
    "        ], dim=-1) \n",
    "\n",
    "        attention_weight = self.attention(attention_input)\n",
    "        hist_attention = torch.sum(attention_weight * hist_movie_embed, dim=1)\n",
    "        \n",
    "        # 拼接所有特征\n",
    "        # print(\"uid_embed维度\", uid_embed.size())\n",
    "        # print(\"gender_embed维度\", gender_embed.size())\n",
    "        # print(\"age_embed维度:\", age_embed.size())\n",
    "        # print(\"job embed维度:\", job_embed.size())\n",
    "        # print(\"movie id embed维度:\", movie_id_embed.size())\n",
    "        # print(\"hist attention维度:\", hist_attention.size())\n",
    "        concat_features = torch.cat([\n",
    "            uid_embed, gender_embed, age_embed, job_embed,\n",
    "            movie_id_embed, hist_attention.unsqueeze(1)\n",
    "        ], dim=1)\n",
    "        # print(\"拼接后的特征维度:\", concat_features.size())\n",
    "        \n",
    "        # 输出预测分数\n",
    "        # print(\"输出数据的数据类型:\", concat_features.dtype)\n",
    "        return self.prediction(concat_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.max_hist_len = max(len(feature[8]) for feature in self.features) # 计算最大历史电影ID列表长度\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        uid = torch.tensor(self.features[idx][0])\n",
    "        movie_id = torch.tensor(self.features[idx][1])\n",
    "        user_gender = torch.tensor(self.features[idx][2])\n",
    "        user_age = torch.tensor(self.features[idx][3])\n",
    "        user_job = torch.tensor(self.features[idx][4])\n",
    "        movie_titles = torch.tensor(self.features[idx][6])\n",
    "        movie_categories = torch.tensor(self.features[idx][7])\n",
    "        history_movie_ids = torch.tensor(self.features[idx][8])\n",
    "\n",
    "        # 这里一定要对history_movie_ids进行填充操作，否则会出现报错（需要保证传入的长度都是一致的）\n",
    "        # 填充操作\n",
    "        padding_len = self.max_hist_len - len(history_movie_ids)\n",
    "        if padding_len > 0:\n",
    "            padding = torch.zeros(padding_len, dtype=torch.long)\n",
    "            history_movie_ids = torch.cat((history_movie_ids, padding), dim=0)\n",
    "        targets = torch.tensor(self.targets[idx]).float()\n",
    "        return uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, history_movie_ids, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备{device}\")\n",
    "\n",
    "class RankModel:\n",
    "    def __init__(self, uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num, max_hist_len):\n",
    "        \"\"\"初始化DIN排序模型\"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # 这里假设DINModel已经定义\n",
    "        self.model = DINModel(uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num, max_hist_len).to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters())\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def train(self, train_loader, num_epochs=5):\n",
    "        \"\"\"训练模型\n",
    "        Args:\n",
    "            train_features: 训练集特征\n",
    "            train_targets: 训练集标签\n",
    "        \"\"\"\n",
    "        print(\"开始训练DIN排序模型...\")\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            for batch_i, (uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, ratings, history_movie_ids) in enumerate(train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                uid = uid.to(device)\n",
    "                user_gender = user_gender.to(device)\n",
    "                user_age = user_age.to(device)\n",
    "                user_job = user_job.to(device)\n",
    "                movie_id = movie_id.to(device)\n",
    "                movie_categories = movie_categories.to(device)\n",
    "                movie_titles = movie_titles.to(device)\n",
    "                history_movie_ids = history_movie_ids.to(device).long() # 这里一定要设置long，否则会出现对history_movie_ids的类型报错，并且要扩充维度\n",
    "                # print(\"ratings的数据类型:\", ratings.dtype)\n",
    "                ratings = ratings.float().to(device)\n",
    "\n",
    "                # 前向传播\n",
    "                outputs = self.model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, history_movie_ids)\n",
    "                loss = self.criterion(outputs, ratings)\n",
    "\n",
    "                # 反向传播和优化\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if (batch_i + 1) % 100 == 0:\n",
    "                    print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{batch_i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "        print(\"训练完成！\")\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        \"\"\"评估模型\n",
    "        Args:\n",
    "            test_loader: 测试集的DataLoader\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        all_predictions = []\n",
    "        all_ratings = []\n",
    "        with torch.no_grad():\n",
    "            for batch_i, (uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, ratings, history_movie_ids) in enumerate(test_loader):\n",
    "                uid = uid.to(self.device)\n",
    "                user_gender = user_gender.to(self.device)\n",
    "                user_age = user_age.to(self.device)\n",
    "                user_job = user_job.to(self.device)\n",
    "                movie_id = movie_id.to(self.device)\n",
    "                movie_categories = movie_categories.to(self.device)\n",
    "                movie_titles = movie_titles.to(self.device)\n",
    "                ratings = ratings.to(self.device)\n",
    "                history_movie_ids=history_movie_ids.to(self.device)\n",
    "                predictions = self.model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles)\n",
    "                all_predictions.extend(predictions.cpu().numpy().flatten())\n",
    "                all_ratings.extend(ratings.cpu().numpy().flatten())\n",
    "\n",
    "        mse = mean_squared_error(all_ratings, all_predictions)\n",
    "        mae = mean_absolute_error(all_ratings, all_predictions)\n",
    "        print(f\"测试集MSE: {mse:.4f}\")\n",
    "        print(f\"测试集MAE: {mae:.4f}\")\n",
    "\n",
    "    def predict(self, features: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"预测评分\n",
    "        Args:\n",
    "            features: 待预测特征\n",
    "        Returns:\n",
    "            预测的评分\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            uid = torch.tensor(features[:, 0].to(self.device))\n",
    "            user_gender = torch.tensor(features[:, 2].to(self.device))\n",
    "            user_age = torch.tensor(features[:, 3].to(self.device))\n",
    "            user_job = torch.tensor(features[:, 4].to(self.device))\n",
    "            movie_id = torch.tensor(features[:, 1].to(self.device))\n",
    "            movie_categories = torch.tensor(features[:, 7].to(self.device))\n",
    "            movie_titles = torch.tensor(features[:, 6].to(self.device))\n",
    "            history_movie_ids = torch.tensor(features[:, 8].to(self.device))\n",
    "\n",
    "            predictions = self.model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, history_movie_ids)\n",
    "            return predictions.cpu().numpy()\n",
    "\n",
    "    def get_recommendations(self, user_features: np.ndarray, recall_movie_features: np.ndarray, top_k: int = 10) -> List[Tuple[int, float]]:\n",
    "        \"\"\"获取推荐电影列表\n",
    "        Args:\n",
    "            user_features: 用户特征\n",
    "            recall_movie_features: 召回的候选电影特征\n",
    "            top_k: 推荐电影数量\n",
    "        Returns:\n",
    "            推荐电影列表，每个元素为(电影ID, 预测评分)\n",
    "        \"\"\"\n",
    "        predictions = self.predict(recall_movie_features)\n",
    "        movie_scores = list(enumerate(predictions))\n",
    "        movie_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return movie_scores[:top_k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_targets, test_features, test_targets=pickle.load(open('./data/split_dataset.p', 'rb'))\n",
    "title2int, title_count, title_set, genres2int, genres_map, features_pd, targets_pd, features, targets_values, ratings_df, users_df, movies_df, data = pickle.load(open('./data/preprocess.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4835, 130, 3852, 2242, 1296, 4153, 3512, 3512...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4809, 4472, 2242, 3869, 1291, 3512, 3512, 351...</td>\n",
       "      <td>[11, 15, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4394, 1320, 1007, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[1951, 4696, 3512, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[722, 932, 973, 3512, 3512, 3512, 3512, 3512, ...</td>\n",
       "      <td>[11, 15, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  gender  age  occupation zip_code  \\\n",
       "0        1      1193       5       1    0          10    48067   \n",
       "1        1       661       3       1    0          10    48067   \n",
       "2        1       914       3       1    0          10    48067   \n",
       "3        1      3408       4       1    0          10    48067   \n",
       "4        1      2355       5       1    0          10    48067   \n",
       "\n",
       "                                               title  \\\n",
       "0  [4835, 130, 3852, 2242, 1296, 4153, 3512, 3512...   \n",
       "1  [4809, 4472, 2242, 3869, 1291, 3512, 3512, 351...   \n",
       "2  [4394, 1320, 1007, 3512, 3512, 3512, 3512, 351...   \n",
       "3  [1951, 4696, 3512, 3512, 3512, 3512, 3512, 351...   \n",
       "4  [722, 932, 973, 3512, 3512, 3512, 3512, 3512, ...   \n",
       "\n",
       "                                              genres  \n",
       "0  [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "1  [11, 15, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...  \n",
       "2  [0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "3  [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "4  [11, 15, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...  "
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_ids = data.groupby('user_id')['movie_id'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1357, 3068, 1537, 647, 2194, 648, 2268, 2628,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[3421, 1641, 648, 1394, 3534, 104, 2735, 1210,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[3468, 1210, 2951, 1214, 1036, 260, 2028, 480,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[2987, 2333, 1175, 39, 288, 2337, 1535, 1392, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6036</td>\n",
       "      <td>[571, 574, 2053, 2054, 2058, 588, 589, 4, 3005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6037</td>\n",
       "      <td>[589, 3006, 1407, 2064, 2065, 593, 3015, 903, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6038</td>\n",
       "      <td>[1419, 920, 3088, 232, 1136, 1148, 1183, 2146,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6039</td>\n",
       "      <td>[588, 2067, 1416, 3022, 3028, 2080, 2083, 2087...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6040</td>\n",
       "      <td>[573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                           movie_id\n",
       "0           1  [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...\n",
       "1           2  [1357, 3068, 1537, 647, 2194, 648, 2268, 2628,...\n",
       "2           3  [3421, 1641, 648, 1394, 3534, 104, 2735, 1210,...\n",
       "3           4  [3468, 1210, 2951, 1214, 1036, 260, 2028, 480,...\n",
       "4           5  [2987, 2333, 1175, 39, 288, 2337, 1535, 1392, ...\n",
       "...       ...                                                ...\n",
       "6035     6036  [571, 574, 2053, 2054, 2058, 588, 589, 4, 3005...\n",
       "6036     6037  [589, 3006, 1407, 2064, 2065, 593, 3015, 903, ...\n",
       "6037     6038  [1419, 920, 3088, 232, 1136, 1148, 1183, 2146,...\n",
       "6038     6039  [588, 2067, 1416, 3022, 3028, 2080, 2083, 2087...\n",
       "6039     6040  [573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...\n",
       "\n",
       "[6040 rows x 2 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在data后增加一列，用来记录用户的历史观看的电影ID\n",
    "new_data = pd.merge(data, user_movie_ids, on='user_id', how='left')\n",
    "\n",
    "# 修改列名\n",
    "new_data=new_data.rename(columns={'movie_id_y':'history_movie_ids', 'movie_id_x': 'movie_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>history_movie_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4835, 130, 3852, 2242, 1296, 4153, 3512, 3512...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4809, 4472, 2242, 3869, 1291, 3512, 3512, 351...</td>\n",
       "      <td>[11, 15, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4394, 1320, 1007, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[1951, 4696, 3512, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[722, 932, 973, 3512, 3512, 3512, 3512, 3512, ...</td>\n",
       "      <td>[11, 15, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  gender  age  occupation zip_code  \\\n",
       "0        1      1193       5       1    0          10    48067   \n",
       "1        1       661       3       1    0          10    48067   \n",
       "2        1       914       3       1    0          10    48067   \n",
       "3        1      3408       4       1    0          10    48067   \n",
       "4        1      2355       5       1    0          10    48067   \n",
       "\n",
       "                                               title  \\\n",
       "0  [4835, 130, 3852, 2242, 1296, 4153, 3512, 3512...   \n",
       "1  [4809, 4472, 2242, 3869, 1291, 3512, 3512, 351...   \n",
       "2  [4394, 1320, 1007, 3512, 3512, 3512, 3512, 351...   \n",
       "3  [1951, 4696, 3512, 3512, 3512, 3512, 3512, 351...   \n",
       "4  [722, 932, 973, 3512, 3512, 3512, 3512, 3512, ...   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "1  [11, 15, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...   \n",
       "2  [0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "3  [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "4  [11, 15, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...   \n",
       "\n",
       "                                   history_movie_ids  \n",
       "0  [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  \n",
       "1  [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  \n",
       "2  [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  \n",
       "3  [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  \n",
       "4  [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'movie_id', 'rating', 'gender', 'age', 'occupation',\n",
       "       'zip_code', 'title', 'genres', 'history_movie_ids'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始划分训练集和测试集...\n",
      "最长的历史电影ID数量为: 2314\n",
      "训练集大小: 800167\n",
      "测试集大小: 200042\n"
     ]
    }
   ],
   "source": [
    "# 从data中划分训练集和测试集\n",
    "print(\"开始划分训练集和测试集...\")\n",
    "\n",
    "# 将数据转换为numpy数组\n",
    "features = np.array(new_data[['user_id', 'movie_id', 'gender', 'age', 'occupation', 'zip_code', 'title', 'genres', 'history_movie_ids']].values)\n",
    "targets = np.array(new_data['rating'].values)\n",
    "\n",
    "max_hist_len = max(len(feature[8]) for feature in features)\n",
    "print(\"最长的历史电影ID数量为:\", max_hist_len)\n",
    "\n",
    "\n",
    "# 使用train_test_split划分训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_targets, test_targets = train_test_split(\n",
    "    features, targets, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {len(train_features)}\")\n",
    "print(f\"测试集大小: {len(test_features)}\")\n",
    "\n",
    "train_dataset=MovieDataset(train_features, train_targets)\n",
    "test_dataset=MovieDataset(test_features, test_targets)\n",
    "train_loader=DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader=DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测层维度: Sequential(\n",
      "  (0): Linear(in_features=57, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "开始训练模型...\n",
      "开始训练DIN排序模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32, 2314])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/25006], Loss: 894242.8125\n",
      "Epoch [1/5], Step [200/25006], Loss: 631314.6875\n",
      "Epoch [1/5], Step [300/25006], Loss: 697570.6875\n",
      "Epoch [1/5], Step [400/25006], Loss: 731132.3750\n",
      "Epoch [1/5], Step [500/25006], Loss: 716335.6875\n",
      "Epoch [1/5], Step [600/25006], Loss: 527838.3125\n",
      "Epoch [1/5], Step [700/25006], Loss: 722588.3750\n",
      "Epoch [1/5], Step [800/25006], Loss: 482378.8438\n",
      "Epoch [1/5], Step [900/25006], Loss: 581806.5625\n",
      "Epoch [1/5], Step [1000/25006], Loss: 643319.1250\n",
      "Epoch [1/5], Step [1100/25006], Loss: 651358.2500\n",
      "Epoch [1/5], Step [1200/25006], Loss: 629393.1250\n",
      "Epoch [1/5], Step [1300/25006], Loss: 682834.6250\n",
      "Epoch [1/5], Step [1400/25006], Loss: 681497.3125\n",
      "Epoch [1/5], Step [1500/25006], Loss: 748875.6250\n",
      "Epoch [1/5], Step [1600/25006], Loss: 648402.3125\n",
      "Epoch [1/5], Step [1700/25006], Loss: 681988.5625\n",
      "Epoch [1/5], Step [1800/25006], Loss: 590061.9375\n",
      "Epoch [1/5], Step [1900/25006], Loss: 583934.3125\n",
      "Epoch [1/5], Step [2000/25006], Loss: 664216.8750\n",
      "Epoch [1/5], Step [2100/25006], Loss: 539550.0625\n",
      "Epoch [1/5], Step [2200/25006], Loss: 655082.9375\n",
      "Epoch [1/5], Step [2300/25006], Loss: 638228.3750\n",
      "Epoch [1/5], Step [2400/25006], Loss: 546795.8750\n",
      "Epoch [1/5], Step [2500/25006], Loss: 404111.8125\n",
      "Epoch [1/5], Step [2600/25006], Loss: 645487.0625\n",
      "Epoch [1/5], Step [2700/25006], Loss: 684602.0625\n",
      "Epoch [1/5], Step [2800/25006], Loss: 576710.5000\n",
      "Epoch [1/5], Step [2900/25006], Loss: 680134.3750\n",
      "Epoch [1/5], Step [3000/25006], Loss: 706913.4375\n",
      "Epoch [1/5], Step [3100/25006], Loss: 736345.7500\n",
      "Epoch [1/5], Step [3200/25006], Loss: 710965.1250\n",
      "Epoch [1/5], Step [3300/25006], Loss: 597881.4375\n",
      "Epoch [1/5], Step [3400/25006], Loss: 555131.2500\n",
      "Epoch [1/5], Step [3500/25006], Loss: 827146.6875\n",
      "Epoch [1/5], Step [3600/25006], Loss: 652237.1250\n",
      "Epoch [1/5], Step [3700/25006], Loss: 586960.0000\n",
      "Epoch [1/5], Step [3800/25006], Loss: 590152.5625\n",
      "Epoch [1/5], Step [3900/25006], Loss: 481903.6250\n",
      "Epoch [1/5], Step [4000/25006], Loss: 602989.5625\n",
      "Epoch [1/5], Step [4100/25006], Loss: 698475.4375\n",
      "Epoch [1/5], Step [4200/25006], Loss: 589502.5000\n",
      "Epoch [1/5], Step [4300/25006], Loss: 765412.8125\n",
      "Epoch [1/5], Step [4400/25006], Loss: 665955.8125\n",
      "Epoch [1/5], Step [4500/25006], Loss: 571797.0625\n",
      "Epoch [1/5], Step [4600/25006], Loss: 549749.3750\n",
      "Epoch [1/5], Step [4700/25006], Loss: 657539.4375\n",
      "Epoch [1/5], Step [4800/25006], Loss: 561256.7500\n",
      "Epoch [1/5], Step [4900/25006], Loss: 551538.6875\n",
      "Epoch [1/5], Step [5000/25006], Loss: 581381.3750\n",
      "Epoch [1/5], Step [5100/25006], Loss: 547023.3125\n",
      "Epoch [1/5], Step [5200/25006], Loss: 590833.8750\n",
      "Epoch [1/5], Step [5300/25006], Loss: 619798.3750\n",
      "Epoch [1/5], Step [5400/25006], Loss: 690905.0000\n",
      "Epoch [1/5], Step [5500/25006], Loss: 620807.4375\n",
      "Epoch [1/5], Step [5600/25006], Loss: 705413.1875\n",
      "Epoch [1/5], Step [5700/25006], Loss: 688507.9375\n",
      "Epoch [1/5], Step [5800/25006], Loss: 687364.8750\n",
      "Epoch [1/5], Step [5900/25006], Loss: 779959.9375\n",
      "Epoch [1/5], Step [6000/25006], Loss: 723174.6250\n",
      "Epoch [1/5], Step [6100/25006], Loss: 665349.9375\n",
      "Epoch [1/5], Step [6200/25006], Loss: 677864.8750\n",
      "Epoch [1/5], Step [6300/25006], Loss: 685177.7500\n",
      "Epoch [1/5], Step [6400/25006], Loss: 479215.2812\n",
      "Epoch [1/5], Step [6500/25006], Loss: 585417.8125\n",
      "Epoch [1/5], Step [6600/25006], Loss: 635909.1875\n",
      "Epoch [1/5], Step [6700/25006], Loss: 721853.9375\n",
      "Epoch [1/5], Step [6800/25006], Loss: 639116.9375\n",
      "Epoch [1/5], Step [6900/25006], Loss: 606471.2500\n",
      "Epoch [1/5], Step [7000/25006], Loss: 608838.6875\n",
      "Epoch [1/5], Step [7100/25006], Loss: 570068.9375\n",
      "Epoch [1/5], Step [7200/25006], Loss: 641056.5000\n",
      "Epoch [1/5], Step [7300/25006], Loss: 697385.8125\n",
      "Epoch [1/5], Step [7400/25006], Loss: 552215.4375\n",
      "Epoch [1/5], Step [7500/25006], Loss: 711857.7500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[370], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m开始训练模型...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mrank_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 评估模型\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m开始评估模型...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[361], line 28\u001b[0m, in \u001b[0;36mRankModel.train\u001b[0;34m(self, train_loader, num_epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_i, (uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, ratings, history_movie_ids) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     30\u001b[0m         uid \u001b[38;5;241m=\u001b[39m uid\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[360], line 20\u001b[0m, in \u001b[0;36mMovieDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m movie_titles \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures[idx][\u001b[38;5;241m6\u001b[39m])\n\u001b[1;32m     19\u001b[0m movie_categories \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures[idx][\u001b[38;5;241m7\u001b[39m])\n\u001b[0;32m---> 20\u001b[0m history_movie_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 这里一定要对history_movie_ids进行填充操作，否则会出现报错（需要保证传入的长度都是一致的）\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 填充操作\u001b[39;00m\n\u001b[1;32m     24\u001b[0m padding_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_hist_len \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(history_movie_ids)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embed_dim = 32\n",
    "# 用户 ID 个数\n",
    "uid_num = max(features.take(0, 1)) + 1\n",
    "# 性别个数\n",
    "gender_num = max(features.take(2, 1)) + 1\n",
    "# 年龄类别个数\n",
    "age_num = max(features.take(3, 1)) + 1\n",
    "# 职业个数\n",
    "job_num = max(features.take(4, 1)) + 1\n",
    "\n",
    "# 电影 ID 个数\n",
    "mid_num = max(features.take(1, 1)) + 1\n",
    "# 电影类型个数\n",
    "movie_category_num = max(genres2int.values()) + 1\n",
    "# 电影名单词个数\n",
    "movie_title_num = len(title_set)\n",
    "\n",
    "# 初始化排序模型\n",
    "rank_model = RankModel(uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num, max_hist_len)\n",
    "\n",
    "# 训练模型\n",
    "print(\"开始训练模型...\")\n",
    "rank_model.train(train_loader)\n",
    "\n",
    "# 评估模型\n",
    "print(\"开始评估模型...\")\n",
    "rank_model.evaluate(test_features, test_targets)\n",
    "\n",
    "# 保存模型\n",
    "save_dir = os.path.join(os.getcwd(), \"model_save\")\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# 获取当前日期作为模型文件名的一部分\n",
    "from datetime import datetime\n",
    "today = datetime.today()\n",
    "formatted_date = today.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 评估模型\n",
    "print(\"开始评估模型...\")\n",
    "rank_model.evaluate(test_features, test_targets)\n",
    "\n",
    "# 保存模型\n",
    "save_dir = os.path.join(os.getcwd(), \"model_save\")\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# 获取当前日期作为模型文件名的一部分\n",
    "from datetime import datetime\n",
    "today = datetime.today()\n",
    "formatted_date = today.strftime('%Y%m%d')\n",
    "\n",
    "# 保存模型\n",
    "model_path = os.path.join(save_dir, f\"rank_model_{formatted_date}.pkl\")\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(rank_model, f)\n",
    "print(f'模型已保存到: {model_path}')\n",
    "\n",
    "# 测试推荐功能\n",
    "print(\"\\n测试推荐功能:\")\n",
    "# 随机选择一个用户\n",
    "test_user_idx = np.random.randint(0, len(test_features))\n",
    "test_user_features = test_features[test_user_idx:test_user_idx+1]\n",
    "\n",
    "# 首先使用召回模型获取候选集\n",
    "with torch.no_grad():\n",
    "    recall_candidates = recall_model.get_recall_candidates(test_user_features, top_k=100)\n",
    "\n",
    "# 获取召回候选集的特征\n",
    "recall_movie_features = test_features[recall_candidates]\n",
    "\n",
    "# 使用排序模型对召回结果进行排序\n",
    "recommendations = rank_model.get_recommendations(test_user_features, recall_movie_features, top_k=5)\n",
    "print(f\"为用户推荐的Top5电影ID及预测评分:\")\n",
    "for movie_id, score in recommendations:\n",
    "    print(f\"电影ID: {movie_id}, 预测评分: {score:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
