{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from typing import List, Tuple\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Dice(nn.Module):\n",
    "    def __init__(self, num_features, epsilon=1e-8):\n",
    "        super(Dice, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(num_features, affine=False)\n",
    "        self.alpha = nn.Parameter(torch.zeros(num_features))\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_normed = self.bn(x)\n",
    "        x_p = torch.sigmoid(self.alpha * (x_normed - x_normed.detach()))\n",
    "        return x * x_p + (1 - x_p) * x_normed\n",
    "\n",
    "\n",
    "class DINModel(nn.Module):\n",
    "    def __init__(self, uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num, embedding_dim=16, attention_units=32):\n",
    "        \"\"\"初始化DIN模型\"\"\"\n",
    "        super(DINModel, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # 用户特征嵌入层\n",
    "        self.uid_embedding = nn.Embedding(uid_num, embedding_dim)\n",
    "        self.gender_embedding = nn.Embedding(gender_num, embedding_dim)\n",
    "        self.age_embedding = nn.Embedding(age_num, embedding_dim)\n",
    "        self.job_embedding = nn.Embedding(job_num, embedding_dim)\n",
    "\n",
    "        # 电影特征嵌入层\n",
    "        self.movie_id_embedding = nn.Embedding(mid_num, embedding_dim)\n",
    "        self.movie_categories_embedding = nn.Embedding(movie_category_num, embedding_dim)\n",
    "        self.movie_title_embedding = nn.Embedding(movie_title_num, embedding_dim)\n",
    "\n",
    "        # 历史电影特征嵌入层\n",
    "        self.history_movie_embedding = nn.Embedding(mid_num, embedding_dim)\n",
    "\n",
    "        # 注意力层\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, attention_units),\n",
    "            Dice(attention_units),\n",
    "            nn.Linear(attention_units, attention_units),\n",
    "            Dice(attention_units),\n",
    "            nn.Linear(attention_units, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # 预测层\n",
    "        self.prediction = nn.Sequential(\n",
    "            nn.Linear(embedding_dim*8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, history_movie_ids):\n",
    "        \"\"\"前向传播\n",
    "        Args:\n",
    "            uid: 用户ID [batch_size] []\n",
    "            user_gender: 用户性别 [batch_size] []\n",
    "            user_age: 用户年龄 [batch_size] []\n",
    "            user_job: 用户职业 [batch_size] []\n",
    "            movie_id: 候选电影ID [batch_size] []\n",
    "            movie_categories: 候选电影类别 [batch_size] [18]\n",
    "            movie_titles: 候选电影标题 [batch_size] [18]\n",
    "            history_movie_ids: 历史交互电影ID [batch_size, hist_len] [2314]\n",
    "        \"\"\"\n",
    "\n",
    "        # 嵌入用户特征\n",
    "        uid_embed = self.uid_embedding(uid)\n",
    "        gender_embed = self.gender_embedding(user_gender)\n",
    "        age_embed = self.age_embedding(user_age)\n",
    "        job_embed = self.job_embedding(user_job)\n",
    "\n",
    "        # 嵌入候选电影特征\n",
    "        movie_id_embed = self.movie_id_embedding(movie_id)\n",
    "        movie_categories_embed = self.movie_categories_embedding(movie_categories)\n",
    "        movie_titles_embed = self.movie_title_embedding(movie_titles)\n",
    "\n",
    "        # 嵌入历史电影ID特征\n",
    "        hist_movie_embed = self.history_movie_embedding(history_movie_ids)\n",
    "\n",
    "        # 注意力机制处理历史交互\n",
    "        attention_input = torch.cat([\n",
    "            movie_id_embed.unsqueeze(1),\n",
    "            hist_movie_embed\n",
    "        ], dim=1)\n",
    "\n",
    "        # 扩展最后一个维度\n",
    "        attention_input_expanded = torch.cat([attention_input, attention_input], dim=-1)\n",
    "\n",
    "        # 调整其维度\n",
    "        batch_size, seq_len, _ = attention_input_expanded.shape\n",
    "        embedding_dim = 16\n",
    "        attention_input_reshaped = attention_input_expanded.view(-1, embedding_dim * 2)\n",
    "        attention_weight = self.attention(attention_input_reshaped)\n",
    "\n",
    "        # 恢复形状\n",
    "        attention_output = attention_weight.view(batch_size, seq_len, 1)\n",
    "\n",
    "        # 调整 attention_output 的维度，使其与 hist_movie_embed 匹配\n",
    "        attention_output = attention_output[:, 1:, :]\n",
    "        hist_attention = torch.sum(attention_output * hist_movie_embed, dim=1)\n",
    "\n",
    "        # 这里的特征维度一定要对齐\n",
    "        movie_categories_embed_mean = torch.mean(movie_categories_embed, dim=1)\n",
    "        movie_titles_embed_mean = torch.mean(movie_titles_embed, dim=1)\n",
    "\n",
    "\n",
    "        # print(\"uid_embed维度:\", uid_embed.size())\n",
    "        # print(\"gender_embed维度:\", gender_embed.size())\n",
    "        # print(\"age_embed维度:\", age_embed.size())\n",
    "        # print(\"job_embed维度:\", job_embed.size())\n",
    "        # print(\"movie_id_embed维度:\", movie_id_embed.size())\n",
    "        # print(\"movie_categories_embed_mean维度:\", movie_categories_embed_mean.size())\n",
    "        # print(\"movie_titles_embed_mean维度:\", movie_titles_embed_mean.size())\n",
    "        # print(\"hist_attention:\", hist_attention.size())\n",
    "        concat_features = torch.cat([\n",
    "            uid_embed,  # [32, 16]\n",
    "            gender_embed, # [32, 16]\n",
    "            age_embed, # [32, 16]\n",
    "            job_embed, # [32, 16]\n",
    "            movie_id_embed,  # [32, 16]\n",
    "            movie_categories_embed_mean,  # [32, 16]\n",
    "            movie_titles_embed_mean, # [32, 16]\n",
    "            hist_attention # [32, 16]\n",
    "        ], dim=1)  #【32, 128]\n",
    "\n",
    "        # 输出预测分数\n",
    "        return self.prediction(concat_features) # [32, 1] 32为一个批次，其中每个值都代表一个预测分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        uid = torch.tensor(self.features[idx][0])\n",
    "        movie_id = torch.tensor(self.features[idx][1])\n",
    "        user_gender = torch.tensor(self.features[idx][2])\n",
    "        user_age = torch.tensor(self.features[idx][3])\n",
    "        user_job = torch.tensor(self.features[idx][4])\n",
    "        movie_titles = torch.tensor(self.features[idx][6])\n",
    "        movie_categories = torch.tensor(self.features[idx][7])\n",
    "        history_movie_ids = torch.tensor(self.features[idx][8])\n",
    "\n",
    "        targets = torch.tensor(self.targets[idx]).float()\n",
    "        return uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, history_movie_ids, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备{device}\")\n",
    "\n",
    "class RankModel:\n",
    "    def __init__(self, uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num):\n",
    "        \"\"\"初始化DIN排序模型\"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = DINModel(uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num).to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters())\n",
    "        self.criterion = nn.MSELoss() # 由MSELoss换成了L1Loss，MSELoss容易受到异常值的影响\n",
    "\n",
    "    def train(self, train_loader, num_epochs=1):\n",
    "        \"\"\"训练模型\n",
    "        Args:\n",
    "            train_features: 训练集特征\n",
    "            train_targets: 训练集标签\n",
    "        \"\"\"\n",
    "        print(\"开始训练DIN排序模型...\")\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            for batch_i, (uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, history_movie_ids, ratings) in enumerate(train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                uid = uid.to(device) # [32] 32表示batch_size\n",
    "                user_gender = user_gender.to(device) # [32] \n",
    "                user_age = user_age.to(device) # [32]\n",
    "                user_job = user_job.to(device) # [32]\n",
    "                movie_id = movie_id.to(device) # [32]\n",
    "                movie_categories = movie_categories.to(device) # [32, 18] 32表示batch_size，18表示电影的类型\n",
    "                movie_titles = movie_titles.to(device) # [32, 15] 32表示batch_size, 15表示每个电影的长度\n",
    "                history_movie_ids = history_movie_ids.to(device).long() # [32, 2314] 但是这里现在是[32]有问题 \n",
    "                ratings = ratings.float().to(device) # [32]\n",
    "\n",
    "                # 前向传播\n",
    "                outputs = self.model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, history_movie_ids)\n",
    "                loss = self.criterion(outputs, ratings)\n",
    "                \n",
    "                # 反向传播和优化\n",
    "                loss.backward()\n",
    "\n",
    "                # # 计算梯度范数（检查是否有出现梯度爆炸）\n",
    "                # total_norm = 0\n",
    "                # for p in self.model.parameters():\n",
    "                #     param_norm = p.grad.data.norm(2)\n",
    "                #     total_norm += param_norm.item() ** 2\n",
    "                # total_norm = total_norm ** (1. / 2)\n",
    "                # print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{batch_i + 1}/{len(train_loader)}], Gradient Norm: {total_norm:.4f}\")\n",
    "\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "\n",
    "                self.optimizer.step()\n",
    "                if (batch_i + 1) % 100 == 0:\n",
    "                    print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{batch_i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "        print(\"训练完成！\")\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        \"\"\"评估模型\n",
    "        Args:\n",
    "            test_loader: 测试集的DataLoader\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        all_predictions = []\n",
    "        all_ratings = []\n",
    "        with torch.no_grad():\n",
    "            for batch_i, (uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, history_movie_ids, ratings) in enumerate(test_loader):\n",
    "                uid = uid.to(self.device)\n",
    "                user_gender = user_gender.to(self.device)\n",
    "                user_age = user_age.to(self.device)\n",
    "                user_job = user_job.to(self.device)\n",
    "                movie_id = movie_id.to(self.device)\n",
    "                movie_categories = movie_categories.to(self.device)\n",
    "                movie_titles = movie_titles.to(self.device)\n",
    "                ratings = ratings.to(self.device)\n",
    "                history_movie_ids=history_movie_ids.to(self.device)\n",
    "                predictions = self.model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles)\n",
    "                all_predictions.extend(predictions.cpu().numpy().flatten())\n",
    "                all_ratings.extend(ratings.cpu().numpy().flatten())\n",
    "\n",
    "        mse = mean_squared_error(all_ratings, all_predictions)\n",
    "        mae = mean_absolute_error(all_ratings, all_predictions)\n",
    "        print(f\"测试集MSE: {mse:.4f}\")\n",
    "        print(f\"测试集MAE: {mae:.4f}\")\n",
    "\n",
    "    def predict(self, features: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"预测评分\n",
    "        Args:\n",
    "            features: 待预测特征\n",
    "        Returns:\n",
    "            预测的评分\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            uid = torch.tensor(features[:, 0].to(self.device))\n",
    "            user_gender = torch.tensor(features[:, 2].to(self.device))\n",
    "            user_age = torch.tensor(features[:, 3].to(self.device))\n",
    "            user_job = torch.tensor(features[:, 4].to(self.device))\n",
    "            movie_id = torch.tensor(features[:, 1].to(self.device))\n",
    "            movie_categories = torch.tensor(features[:, 7].to(self.device))\n",
    "            movie_titles = torch.tensor(features[:, 6].to(self.device))\n",
    "            history_movie_ids = torch.tensor(features[:, 8].to(self.device))\n",
    "\n",
    "            predictions = self.model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, history_movie_ids)\n",
    "            return predictions.cpu().numpy()\n",
    "\n",
    "    def get_recommendations(self, user_features: np.ndarray, recall_movie_features: np.ndarray, top_k: int = 10) -> List[Tuple[int, float]]:\n",
    "        \"\"\"获取推荐电影列表\n",
    "        Args:\n",
    "            user_features: 用户特征\n",
    "            recall_movie_features: 召回的候选电影特征\n",
    "            top_k: 推荐电影数量\n",
    "        Returns:\n",
    "            推荐电影列表，每个元素为(电影ID, 预测评分)\n",
    "        \"\"\"\n",
    "        predictions = self.predict(recall_movie_features)\n",
    "        movie_scores = list(enumerate(predictions))\n",
    "        movie_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return movie_scores[:top_k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_targets, test_features, test_targets=pickle.load(open('./data/split_dataset.p', 'rb'))\n",
    "title2int, title_count, title_set, genres2int, genres_map, features_pd, targets_pd, features, targets_values, ratings_df, users_df, movies_df, data = pickle.load(open('./data/preprocess.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4835, 130, 3852, 2242, 1296, 4153, 3512, 3512...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4809, 4472, 2242, 3869, 1291, 3512, 3512, 351...</td>\n",
       "      <td>[11, 15, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4394, 1320, 1007, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[1951, 4696, 3512, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[722, 932, 973, 3512, 3512, 3512, 3512, 3512, ...</td>\n",
       "      <td>[11, 15, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  gender  age  occupation zip_code  \\\n",
       "0        1      1193       5       1    0          10    48067   \n",
       "1        1       661       3       1    0          10    48067   \n",
       "2        1       914       3       1    0          10    48067   \n",
       "3        1      3408       4       1    0          10    48067   \n",
       "4        1      2355       5       1    0          10    48067   \n",
       "\n",
       "                                               title  \\\n",
       "0  [4835, 130, 3852, 2242, 1296, 4153, 3512, 3512...   \n",
       "1  [4809, 4472, 2242, 3869, 1291, 3512, 3512, 351...   \n",
       "2  [4394, 1320, 1007, 3512, 3512, 3512, 3512, 351...   \n",
       "3  [1951, 4696, 3512, 3512, 3512, 3512, 3512, 351...   \n",
       "4  [722, 932, 973, 3512, 3512, 3512, 3512, 3512, ...   \n",
       "\n",
       "                                              genres  \n",
       "0  [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "1  [11, 15, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...  \n",
       "2  [0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "3  [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "4  [11, 15, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_ids = data.groupby('user_id')['movie_id'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在data后增加一列，用来记录用户的历史观看的电影ID\n",
    "new_data = pd.merge(data, user_movie_ids, on='user_id', how='left')\n",
    "\n",
    "# 修改列名\n",
    "new_data=new_data.rename(columns={'movie_id_y':'history_movie_ids', 'movie_id_x': 'movie_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>history_movie_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4835, 130, 3852, 2242, 1296, 4153, 3512, 3512...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4809, 4472, 2242, 3869, 1291, 3512, 3512, 351...</td>\n",
       "      <td>[11, 15, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4394, 1320, 1007, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[1951, 4696, 3512, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[722, 932, 973, 3512, 3512, 3512, 3512, 3512, ...</td>\n",
       "      <td>[11, 15, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "      <td>[5025, 378, 4350, 3512, 3512, 3512, 3512, 3512...</td>\n",
       "      <td>[6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "      <td>[3690, 1768, 4315, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[4, 5, 12, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,...</td>\n",
       "      <td>[573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "      <td>[1050, 390, 2242, 314, 3512, 3512, 3512, 3512,...</td>\n",
       "      <td>[6, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "      <td>[2220, 766, 3512, 3512, 3512, 3512, 3512, 3512...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "      <td>[2950, 2242, 585, 3512, 3512, 3512, 3512, 3512...</td>\n",
       "      <td>[15, 4, 3, 18, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "      <td>[573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  movie_id  rating  gender  age  occupation zip_code  \\\n",
       "0              1      1193       5       1    0          10    48067   \n",
       "1              1       661       3       1    0          10    48067   \n",
       "2              1       914       3       1    0          10    48067   \n",
       "3              1      3408       4       1    0          10    48067   \n",
       "4              1      2355       5       1    0          10    48067   \n",
       "...          ...       ...     ...     ...  ...         ...      ...   \n",
       "1000204     6040      1091       1       0    6           6    11106   \n",
       "1000205     6040      1094       5       0    6           6    11106   \n",
       "1000206     6040       562       5       0    6           6    11106   \n",
       "1000207     6040      1096       4       0    6           6    11106   \n",
       "1000208     6040      1097       4       0    6           6    11106   \n",
       "\n",
       "                                                     title  \\\n",
       "0        [4835, 130, 3852, 2242, 1296, 4153, 3512, 3512...   \n",
       "1        [4809, 4472, 2242, 3869, 1291, 3512, 3512, 351...   \n",
       "2        [4394, 1320, 1007, 3512, 3512, 3512, 3512, 351...   \n",
       "3        [1951, 4696, 3512, 3512, 3512, 3512, 3512, 351...   \n",
       "4        [722, 932, 973, 3512, 3512, 3512, 3512, 3512, ...   \n",
       "...                                                    ...   \n",
       "1000204  [5025, 378, 4350, 3512, 3512, 3512, 3512, 3512...   \n",
       "1000205  [3690, 1768, 4315, 3512, 3512, 3512, 3512, 351...   \n",
       "1000206  [1050, 390, 2242, 314, 3512, 3512, 3512, 3512,...   \n",
       "1000207  [2220, 766, 3512, 3512, 3512, 3512, 3512, 3512...   \n",
       "1000208  [2950, 2242, 585, 3512, 3512, 3512, 3512, 3512...   \n",
       "\n",
       "                                                    genres  \\\n",
       "0        [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "1        [11, 15, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...   \n",
       "2        [0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "3        [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "4        [11, 15, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...   \n",
       "...                                                    ...   \n",
       "1000204  [6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "1000205  [4, 5, 12, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,...   \n",
       "1000206  [6, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "1000207  [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "1000208  [15, 4, 3, 18, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...   \n",
       "\n",
       "                                         history_movie_ids  \n",
       "0        [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  \n",
       "1        [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  \n",
       "2        [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  \n",
       "3        [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  \n",
       "4        [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  \n",
       "...                                                    ...  \n",
       "1000204  [573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...  \n",
       "1000205  [573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...  \n",
       "1000206  [573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...  \n",
       "1000207  [573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...  \n",
       "1000208  [573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...  \n",
       "\n",
       "[1000209 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最长的历史电影ID数量为: 2314\n",
      "这些数组仍未被填充: []\n"
     ]
    }
   ],
   "source": [
    "# 填充new_data的history_movie_ids列\n",
    "# 1. 找到history_movie_ids最长是多少\n",
    "max_hist_len = max([len(arr) for arr in new_data['history_movie_ids']])\n",
    "print(\"最长的历史电影ID数量为:\", max_hist_len)\n",
    "\n",
    "# 2. 对history_movie_ids进行填充操作\n",
    "def pad_array(arr):\n",
    "    arr_len = len(arr)\n",
    "    if arr_len < max_hist_len:\n",
    "        # 选择数组中的第一个元素进行填充（你也可以按需选择其他元素）\n",
    "        fill_element = arr[0]\n",
    "        padding = [fill_element] * (max_hist_len - arr_len)\n",
    "        arr = arr + padding\n",
    "    return arr\n",
    "\n",
    "new_data['history_movie_ids'] = new_data['history_movie_ids'].apply(pad_array)\n",
    "\n",
    "# 3. 检查填充后的结果\n",
    "wrong_ids=[len(arr) for arr in new_data['history_movie_ids'] if len(arr)!=max_hist_len]\n",
    "print(\"这些数组仍未被填充:\", wrong_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始划分训练集和测试集...\n",
      "训练集大小: 800167\n",
      "测试集大小: 200042\n"
     ]
    }
   ],
   "source": [
    "# 从data中划分训练集和测试集\n",
    "print(\"开始划分训练集和测试集...\")\n",
    "\n",
    "# 将数据转换为numpy数组\n",
    "features = np.array(new_data[['user_id', 'movie_id', 'gender', 'age', 'occupation', 'zip_code', 'title', 'genres', 'history_movie_ids']].values)\n",
    "targets = np.array(new_data['rating'].values)\n",
    "\n",
    "\n",
    "# 使用train_test_split划分训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_targets, test_targets = train_test_split(\n",
    "    features, targets, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {len(train_features)}\")\n",
    "print(f\"测试集大小: {len(test_features)}\")\n",
    "\n",
    "train_dataset=MovieDataset(train_features, train_targets)\n",
    "test_dataset=MovieDataset(test_features, test_targets)\n",
    "train_loader=DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader=DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练模型...\n",
      "开始训练DIN排序模型...\n",
      "tensor([[19.0501],\n",
      "        [13.8386],\n",
      "        [24.3832],\n",
      "        [12.3352],\n",
      "        [-0.6534],\n",
      "        [ 5.2152],\n",
      "        [20.4401],\n",
      "        [ 1.3969],\n",
      "        [ 2.5308],\n",
      "        [14.6218],\n",
      "        [15.8792],\n",
      "        [17.0965],\n",
      "        [13.6421],\n",
      "        [19.1898],\n",
      "        [ 9.1909],\n",
      "        [19.5670],\n",
      "        [15.7434],\n",
      "        [ 5.1342],\n",
      "        [ 9.1098],\n",
      "        [19.5534],\n",
      "        [16.9151],\n",
      "        [15.0710],\n",
      "        [ 9.4064],\n",
      "        [14.0158],\n",
      "        [17.3884],\n",
      "        [10.8099],\n",
      "        [24.0973],\n",
      "        [22.0580],\n",
      "        [10.8824],\n",
      "        [30.3168],\n",
      "        [ 1.2404],\n",
      "        [32.3196]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-16.3930],\n",
      "        [  5.2276],\n",
      "        [-10.6737],\n",
      "        [-33.2332],\n",
      "        [  3.9253],\n",
      "        [  1.8616],\n",
      "        [-12.5809],\n",
      "        [-57.1403],\n",
      "        [-13.8580],\n",
      "        [-37.2405],\n",
      "        [-11.7787],\n",
      "        [ -5.1425],\n",
      "        [-16.5109],\n",
      "        [-16.4884],\n",
      "        [-12.6588],\n",
      "        [-15.8589],\n",
      "        [-14.8158],\n",
      "        [-15.9982],\n",
      "        [  5.9875],\n",
      "        [-27.3289],\n",
      "        [ -8.3030],\n",
      "        [-19.5943],\n",
      "        [ -0.2212],\n",
      "        [ -8.3382],\n",
      "        [-17.8666],\n",
      "        [ -1.3928],\n",
      "        [-35.5565],\n",
      "        [-19.6076],\n",
      "        [-15.8261],\n",
      "        [ -8.6585],\n",
      "        [-17.8631],\n",
      "        [-15.0381]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-14.8529],\n",
      "        [-11.5616],\n",
      "        [  9.7153],\n",
      "        [  2.4869],\n",
      "        [-21.9541],\n",
      "        [ -4.1902],\n",
      "        [-50.8552],\n",
      "        [ -8.6933],\n",
      "        [-10.7063],\n",
      "        [-15.3069],\n",
      "        [-21.3855],\n",
      "        [  2.1176],\n",
      "        [  1.2290],\n",
      "        [-24.6531],\n",
      "        [-21.8535],\n",
      "        [-12.5852],\n",
      "        [  7.8755],\n",
      "        [  8.7486],\n",
      "        [-15.7503],\n",
      "        [ -8.5261],\n",
      "        [-18.4338],\n",
      "        [-10.7295],\n",
      "        [  6.4424],\n",
      "        [-16.3629],\n",
      "        [-13.5742],\n",
      "        [-13.8079],\n",
      "        [-12.7844],\n",
      "        [  0.1663],\n",
      "        [ -3.6707],\n",
      "        [-13.3660],\n",
      "        [-29.2587],\n",
      "        [-13.4419]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ -6.9825],\n",
      "        [-14.8843],\n",
      "        [ -1.6207],\n",
      "        [ -0.9453],\n",
      "        [ -1.3842],\n",
      "        [ -7.0050],\n",
      "        [  6.4003],\n",
      "        [ -0.8092],\n",
      "        [ -1.5527],\n",
      "        [ -1.2619],\n",
      "        [-15.2543],\n",
      "        [ -1.8621],\n",
      "        [ -0.9136],\n",
      "        [ -1.3568],\n",
      "        [ -1.3287],\n",
      "        [ -8.1834],\n",
      "        [ -1.4817],\n",
      "        [ -1.4824],\n",
      "        [-14.6193],\n",
      "        [  1.9589],\n",
      "        [ -6.7913],\n",
      "        [ -1.1927],\n",
      "        [ -1.1153],\n",
      "        [ -6.3679],\n",
      "        [ 46.3684],\n",
      "        [ -7.4048],\n",
      "        [ -0.3142],\n",
      "        [ -6.6050],\n",
      "        [ -1.8555],\n",
      "        [ -9.0566],\n",
      "        [ -5.7548],\n",
      "        [  5.6334]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 15.8277],\n",
      "        [  7.0853],\n",
      "        [ 32.8319],\n",
      "        [-20.7281],\n",
      "        [ 13.5914],\n",
      "        [ 10.8055],\n",
      "        [  7.7994],\n",
      "        [  7.5895],\n",
      "        [  6.6990],\n",
      "        [ -6.1002],\n",
      "        [ -3.6998],\n",
      "        [ -0.6693],\n",
      "        [  9.0187],\n",
      "        [  8.8523],\n",
      "        [  9.0225],\n",
      "        [  8.1902],\n",
      "        [  7.7319],\n",
      "        [ -5.0231],\n",
      "        [ -8.1091],\n",
      "        [ 13.6758],\n",
      "        [ 14.6391],\n",
      "        [-16.3702],\n",
      "        [  8.4005],\n",
      "        [ 11.0413],\n",
      "        [  7.2107],\n",
      "        [ -4.0080],\n",
      "        [  7.9516],\n",
      "        [ 10.6641],\n",
      "        [ 12.6059],\n",
      "        [  3.1467],\n",
      "        [ 15.2787],\n",
      "        [ 29.6261]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1.9614],\n",
      "        [  7.3069],\n",
      "        [ 11.1682],\n",
      "        [ 14.7204],\n",
      "        [ 16.1641],\n",
      "        [  1.3903],\n",
      "        [ 11.9171],\n",
      "        [ 14.9484],\n",
      "        [ 15.9068],\n",
      "        [ 34.4283],\n",
      "        [ -2.8369],\n",
      "        [ 17.3245],\n",
      "        [ 11.5751],\n",
      "        [-32.9911],\n",
      "        [ 18.6683],\n",
      "        [  5.0113],\n",
      "        [ 13.9790],\n",
      "        [ 16.1648],\n",
      "        [  8.5095],\n",
      "        [  5.2825],\n",
      "        [ 17.4568],\n",
      "        [  8.4366],\n",
      "        [ 16.3792],\n",
      "        [  2.1279],\n",
      "        [  6.0077],\n",
      "        [ 15.5771],\n",
      "        [  9.0636],\n",
      "        [ 12.4615],\n",
      "        [  6.2624],\n",
      "        [ 13.3301],\n",
      "        [ 13.3181],\n",
      "        [ 15.0712]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[11.7904],\n",
      "        [ 2.5867],\n",
      "        [10.7107],\n",
      "        [16.9469],\n",
      "        [16.5344],\n",
      "        [ 9.8922],\n",
      "        [15.1563],\n",
      "        [13.2575],\n",
      "        [11.0797],\n",
      "        [12.3978],\n",
      "        [13.4082],\n",
      "        [-9.3910],\n",
      "        [63.0805],\n",
      "        [ 1.7901],\n",
      "        [11.8766],\n",
      "        [13.0909],\n",
      "        [13.0477],\n",
      "        [17.9176],\n",
      "        [12.1937],\n",
      "        [16.0083],\n",
      "        [ 7.8030],\n",
      "        [ 6.6847],\n",
      "        [ 9.0720],\n",
      "        [13.0495],\n",
      "        [ 9.8258],\n",
      "        [30.7164],\n",
      "        [-2.9906],\n",
      "        [ 9.9817],\n",
      "        [ 8.5877],\n",
      "        [ 6.6553],\n",
      "        [11.2199],\n",
      "        [ 8.8939]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[11.6733],\n",
      "        [ 2.9058],\n",
      "        [15.3125],\n",
      "        [ 0.4849],\n",
      "        [ 4.7985],\n",
      "        [ 4.5682],\n",
      "        [ 3.2510],\n",
      "        [ 3.9225],\n",
      "        [ 7.9063],\n",
      "        [18.4549],\n",
      "        [ 4.5505],\n",
      "        [ 3.6464],\n",
      "        [ 5.2065],\n",
      "        [21.6479],\n",
      "        [14.4171],\n",
      "        [ 3.2107],\n",
      "        [11.5752],\n",
      "        [13.7701],\n",
      "        [ 3.8143],\n",
      "        [ 5.7431],\n",
      "        [ 5.9057],\n",
      "        [23.5938],\n",
      "        [ 0.4754],\n",
      "        [ 4.6686],\n",
      "        [30.7910],\n",
      "        [ 3.8836],\n",
      "        [ 7.7840],\n",
      "        [ 4.5445],\n",
      "        [11.5215],\n",
      "        [ 4.6604],\n",
      "        [15.1539],\n",
      "        [ 6.4352]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[  6.2640],\n",
      "        [ -5.1718],\n",
      "        [  5.6631],\n",
      "        [ -3.0402],\n",
      "        [ -3.7683],\n",
      "        [ -5.0129],\n",
      "        [  9.4167],\n",
      "        [ -4.4433],\n",
      "        [ -4.1397],\n",
      "        [ -7.1879],\n",
      "        [-16.4248],\n",
      "        [ -4.7840],\n",
      "        [ -3.5815],\n",
      "        [  6.4177],\n",
      "        [  0.2948],\n",
      "        [ -3.4479],\n",
      "        [  6.9860],\n",
      "        [ -4.7822],\n",
      "        [ 17.0534],\n",
      "        [ 19.5508],\n",
      "        [ -4.2207],\n",
      "        [ -4.0507],\n",
      "        [ -3.5450],\n",
      "        [ -0.2199],\n",
      "        [ -4.3841],\n",
      "        [ -4.2926],\n",
      "        [ -4.6415],\n",
      "        [ -5.2827],\n",
      "        [ -4.7169],\n",
      "        [ -4.1773],\n",
      "        [  0.2201],\n",
      "        [ 19.4461]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ -1.7159],\n",
      "        [ -5.6861],\n",
      "        [  0.6811],\n",
      "        [ -7.8965],\n",
      "        [ -5.1039],\n",
      "        [ -0.9538],\n",
      "        [  7.2938],\n",
      "        [ -6.1494],\n",
      "        [ -7.1281],\n",
      "        [ -6.0348],\n",
      "        [ -8.5371],\n",
      "        [ -6.7903],\n",
      "        [  2.2941],\n",
      "        [ -7.9544],\n",
      "        [ -2.1799],\n",
      "        [ -1.2020],\n",
      "        [ -8.7099],\n",
      "        [  7.3757],\n",
      "        [ -5.9728],\n",
      "        [  2.3934],\n",
      "        [  2.3276],\n",
      "        [  0.9000],\n",
      "        [  6.3106],\n",
      "        [ 25.9351],\n",
      "        [ 11.4848],\n",
      "        [ 10.4620],\n",
      "        [ -5.6629],\n",
      "        [-15.9727],\n",
      "        [ -8.5804],\n",
      "        [ -5.9074],\n",
      "        [ -1.4225],\n",
      "        [ -4.6195]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ -1.1175],\n",
      "        [ -1.9682],\n",
      "        [ -4.8471],\n",
      "        [ -5.2073],\n",
      "        [  4.1533],\n",
      "        [ -1.6249],\n",
      "        [ -5.2257],\n",
      "        [ 26.5874],\n",
      "        [ -2.8490],\n",
      "        [ -5.2671],\n",
      "        [ -2.6507],\n",
      "        [ -2.8992],\n",
      "        [ -0.9474],\n",
      "        [ -1.9468],\n",
      "        [ -2.9657],\n",
      "        [ -5.8113],\n",
      "        [ -5.6665],\n",
      "        [ -2.6611],\n",
      "        [-18.8484],\n",
      "        [ -3.2910],\n",
      "        [-13.6950],\n",
      "        [ -1.2400],\n",
      "        [ -2.5355],\n",
      "        [ -1.0287],\n",
      "        [ -8.4691],\n",
      "        [  1.6618],\n",
      "        [ -2.8928],\n",
      "        [ -2.6024],\n",
      "        [ -7.8605],\n",
      "        [ -2.6099],\n",
      "        [ 11.4343],\n",
      "        [ -1.0352]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 4.8397e+00],\n",
      "        [ 5.1920e-02],\n",
      "        [ 2.7871e-01],\n",
      "        [ 7.5041e-01],\n",
      "        [ 7.0995e-02],\n",
      "        [-7.1539e-02],\n",
      "        [ 3.1432e+00],\n",
      "        [ 4.8249e+00],\n",
      "        [-8.2861e+00],\n",
      "        [ 2.3302e+00],\n",
      "        [-1.6456e+00],\n",
      "        [ 5.8738e-02],\n",
      "        [ 4.1887e-01],\n",
      "        [ 5.6571e-01],\n",
      "        [ 1.9509e+01],\n",
      "        [ 6.0167e+00],\n",
      "        [-3.3795e-01],\n",
      "        [ 7.8586e-01],\n",
      "        [-6.0426e-02],\n",
      "        [-5.6580e-01],\n",
      "        [ 2.0395e-01],\n",
      "        [ 2.3243e-01],\n",
      "        [-7.6726e+00],\n",
      "        [ 4.7451e-01],\n",
      "        [ 8.8571e+00],\n",
      "        [ 7.8169e-01],\n",
      "        [ 1.4413e+01],\n",
      "        [-1.5643e-01],\n",
      "        [ 3.4044e-01],\n",
      "        [ 9.0387e+00],\n",
      "        [-2.2902e-03],\n",
      "        [ 3.8506e-01]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[  6.3125],\n",
      "        [  8.8371],\n",
      "        [ -6.8200],\n",
      "        [ -0.1010],\n",
      "        [ -5.1339],\n",
      "        [  5.8105],\n",
      "        [  6.7936],\n",
      "        [  2.4861],\n",
      "        [  8.4512],\n",
      "        [  5.1503],\n",
      "        [  7.3228],\n",
      "        [  7.6121],\n",
      "        [ 27.0705],\n",
      "        [  7.9523],\n",
      "        [  7.2442],\n",
      "        [  3.4878],\n",
      "        [  7.2306],\n",
      "        [  6.6771],\n",
      "        [  6.9924],\n",
      "        [ -3.6867],\n",
      "        [-25.2530],\n",
      "        [  6.8657],\n",
      "        [ -2.2274],\n",
      "        [ -3.5409],\n",
      "        [ -6.6728],\n",
      "        [ 16.2819],\n",
      "        [  1.6738],\n",
      "        [ -0.1020],\n",
      "        [ 22.5298],\n",
      "        [  5.6772],\n",
      "        [  8.9625],\n",
      "        [  0.0875]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 4.0084],\n",
      "        [ 0.0472],\n",
      "        [ 4.4007],\n",
      "        [10.6815],\n",
      "        [ 7.7457],\n",
      "        [15.8995],\n",
      "        [ 5.4015],\n",
      "        [ 0.2784],\n",
      "        [ 8.9559],\n",
      "        [11.3717],\n",
      "        [10.4607],\n",
      "        [10.5881],\n",
      "        [11.1072],\n",
      "        [16.7206],\n",
      "        [10.5932],\n",
      "        [ 8.9756],\n",
      "        [ 5.5216],\n",
      "        [13.2659],\n",
      "        [ 4.5336],\n",
      "        [14.4526],\n",
      "        [11.2815],\n",
      "        [-2.7889],\n",
      "        [ 3.9557],\n",
      "        [10.2998],\n",
      "        [14.0037],\n",
      "        [-9.4270],\n",
      "        [12.4498],\n",
      "        [ 1.1240],\n",
      "        [ 7.5080],\n",
      "        [ 1.9634],\n",
      "        [ 4.1673],\n",
      "        [ 8.9682]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[18.5482],\n",
      "        [ 6.9320],\n",
      "        [-4.0760],\n",
      "        [13.1491],\n",
      "        [ 5.1797],\n",
      "        [ 4.5818],\n",
      "        [ 9.8633],\n",
      "        [ 5.7026],\n",
      "        [12.6480],\n",
      "        [11.1607],\n",
      "        [ 7.1364],\n",
      "        [ 0.5028],\n",
      "        [18.5053],\n",
      "        [ 6.7049],\n",
      "        [12.6428],\n",
      "        [ 2.0747],\n",
      "        [ 8.8807],\n",
      "        [ 8.5317],\n",
      "        [11.7403],\n",
      "        [19.0618],\n",
      "        [12.3865],\n",
      "        [-4.8827],\n",
      "        [-1.6672],\n",
      "        [-3.6446],\n",
      "        [ 9.4942],\n",
      "        [ 9.3641],\n",
      "        [ 9.9133],\n",
      "        [ 7.2968],\n",
      "        [ 8.6246],\n",
      "        [ 7.0844],\n",
      "        [11.7906],\n",
      "        [11.3486]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 19.6408],\n",
      "        [ -2.2959],\n",
      "        [  6.6448],\n",
      "        [  4.9756],\n",
      "        [  3.5797],\n",
      "        [  7.6668],\n",
      "        [  2.8090],\n",
      "        [  7.6115],\n",
      "        [  6.2662],\n",
      "        [  4.1473],\n",
      "        [  5.8856],\n",
      "        [  3.7084],\n",
      "        [  8.6009],\n",
      "        [  7.0847],\n",
      "        [ -4.1656],\n",
      "        [  2.4149],\n",
      "        [-17.4120],\n",
      "        [  6.3225],\n",
      "        [  8.9650],\n",
      "        [  6.3149],\n",
      "        [  5.8422],\n",
      "        [  2.0227],\n",
      "        [ -0.9064],\n",
      "        [  7.4206],\n",
      "        [  8.7800],\n",
      "        [  6.9094],\n",
      "        [  9.9293],\n",
      "        [  5.7045],\n",
      "        [  4.1849],\n",
      "        [  7.1739],\n",
      "        [ -4.7515],\n",
      "        [  4.3009]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 2.4985],\n",
      "        [-9.2837],\n",
      "        [ 2.1097],\n",
      "        [ 8.5664],\n",
      "        [ 2.2490],\n",
      "        [-5.5709],\n",
      "        [ 1.7275],\n",
      "        [-7.2420],\n",
      "        [-2.9220],\n",
      "        [11.0004],\n",
      "        [11.6795],\n",
      "        [ 1.5041],\n",
      "        [-9.7171],\n",
      "        [-3.9740],\n",
      "        [ 1.9525],\n",
      "        [ 1.8147],\n",
      "        [-0.6101],\n",
      "        [ 2.3350],\n",
      "        [ 3.2449],\n",
      "        [ 1.5533],\n",
      "        [ 5.4328],\n",
      "        [-5.0123],\n",
      "        [ 1.4428],\n",
      "        [ 1.9027],\n",
      "        [ 5.5088],\n",
      "        [ 5.0940],\n",
      "        [ 5.9730],\n",
      "        [ 9.2010],\n",
      "        [ 8.1173],\n",
      "        [ 6.0807],\n",
      "        [ 1.9861],\n",
      "        [-3.8500]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[204], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m开始训练模型...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mrank_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# # 评估模型\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# print(\"开始评估模型...\")\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# rank_model.evaluate(test_features, test_targets)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# today = datetime.today()\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# formatted_date = today.strftime('%Y%m%d')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[197], line 44\u001b[0m, in \u001b[0;36mRankModel.train\u001b[0;34m(self, train_loader, num_epochs)\u001b[0m\n\u001b[1;32m     41\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, ratings)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# 反向传播和优化\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# # 计算梯度范数（检查是否有出现梯度爆炸）\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# total_norm = 0\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# for p in self.model.parameters():\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# total_norm = total_norm ** (1. / 2)\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{batch_i + 1}/{len(train_loader)}], Gradient Norm: {total_norm:.4f}\")\u001b[39;00m\n\u001b[1;32m     55\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embed_dim = 32\n",
    "# 用户 ID 个数\n",
    "uid_num = max(features.take(0, 1)) + 1\n",
    "# 性别个数\n",
    "gender_num = max(features.take(2, 1)) + 1\n",
    "# 年龄类别个数\n",
    "age_num = max(features.take(3, 1)) + 1\n",
    "# 职业个数\n",
    "job_num = max(features.take(4, 1)) + 1\n",
    "\n",
    "# 电影 ID 个数\n",
    "mid_num = max(features.take(1, 1)) + 1\n",
    "# 电影类型个数\n",
    "movie_category_num = max(genres2int.values()) + 1\n",
    "# 电影名单词个数\n",
    "movie_title_num = len(title_set)\n",
    "\n",
    "# 初始化排序模型\n",
    "rank_model = RankModel(uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num)\n",
    "\n",
    "# 训练模型\n",
    "print(\"开始训练模型...\")\n",
    "rank_model.train(train_loader)\n",
    "\n",
    "# # 评估模型\n",
    "# print(\"开始评估模型...\")\n",
    "# rank_model.evaluate(test_features, test_targets)\n",
    "\n",
    "# # 保存模型\n",
    "# save_dir = os.path.join(os.getcwd(), \"model_save\")\n",
    "# if not os.path.exists(save_dir):\n",
    "#     os.makedirs(save_dir)\n",
    "\n",
    "# # 获取当前日期作为模型文件名的一部分\n",
    "# from datetime import datetime\n",
    "# today = datetime.today()\n",
    "# formatted_date = today.strftime('%Y%m%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
