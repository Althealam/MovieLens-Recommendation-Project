{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from typing import List, Tuple\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DINModel(nn.Module):\n",
    "    def __init__(self, uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num, max_hist_len, embedding_dim=16, attention_units=32):\n",
    "        \"\"\"初始化DIN模型\"\"\"\n",
    "        super(DINModel, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # 用户特征嵌入层\n",
    "        self.uid_embedding = nn.Embedding(uid_num, embedding_dim)\n",
    "        self.gender_embedding = nn.Embedding(gender_num, embedding_dim//2)\n",
    "        self.age_embedding = nn.Embedding(age_num, embedding_dim//2)\n",
    "        self.job_embedding = nn.Embedding(job_num, embedding_dim//2)\n",
    "\n",
    "        # 电影特征嵌入层\n",
    "        self.movie_id_embedding = nn.Embedding(mid_num, embedding_dim)\n",
    "        self.movie_categories_embedding = nn.Embedding(movie_category_num, embedding_dim)\n",
    "        \n",
    "        self.movie_title_embedding = nn.Embedding(movie_title_num, embedding_dim//2)\n",
    "\n",
    "        self.history_movie_embedding = nn.Embedding(max_hist_len, embedding_dim)\n",
    "        # 注意力层\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, attention_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(attention_units, attention_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(attention_units, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # 预测层\n",
    "        self.prediction = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 6, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, history_movie_ids):\n",
    "        \"\"\"前向传播\n",
    "        Args:\n",
    "            uid: 用户ID [batch_size]\n",
    "            user_gender: 用户性别 [batch_size]\n",
    "            user_age: 用户年龄 [batch_size]\n",
    "            user_job: 用户职业 [batch_size]\n",
    "            movie_id: 候选电影ID [batch_size]\n",
    "            movie_categories: 候选电影类别 [batch_size]\n",
    "            movie_titles: 候选电影标题 [batch_size]\n",
    "            history_movie_ids: 历史交互电影ID [batch_size, hist_len]\n",
    "        \"\"\"\n",
    "        # 嵌入用户特征\n",
    "        uid_embed = self.uid_embedding(uid)\n",
    "        gender_embed = self.gender_embedding(user_gender)\n",
    "        age_embed = self.age_embedding(user_age)\n",
    "        job_embed = self.job_embedding(user_job)\n",
    "        \n",
    "        # 嵌入候选电影特征\n",
    "        movie_id_embed = self.movie_id_embedding(movie_id)\n",
    "        print(\"电影ID维度:\", movie_id_embed.size())\n",
    "        movie_categories_embed = self.movie_categories_embedding(movie_categories)\n",
    "        movie_titles_embed = self.movie_title_embedding(movie_titles)\n",
    "        \n",
    "        # 嵌入历史电影ID特征\n",
    "        hist_movie_embed = self.movie_id_embedding(history_movie_ids)\n",
    "        print('历史电影ID维度:', hist_movie_embed.size())\n",
    "        # 注意力机制处理历史交互\n",
    "        attention_input = torch.cat([\n",
    "            movie_id_embed.unsqueeze(1).expand(-1, hist_movie_embed.size(1), -1),\n",
    "            hist_movie_embed\n",
    "        ], dim=-1)\n",
    "        \n",
    "        attention_weight = self.attention(attention_input)\n",
    "        hist_attention = torch.sum(attention_weight * hist_movie_embed, dim=1)\n",
    "        \n",
    "        # 拼接所有特征\n",
    "        concat_features = torch.cat([\n",
    "            uid_embed, gender_embed, age_embed, job_embed,\n",
    "            movie_id_embed, hist_attention\n",
    "        ], dim=1)\n",
    "        \n",
    "        # 输出预测分数\n",
    "        return self.prediction(concat_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.max_hist_len = max(len(feature[8]) for feature in self.features) # 计算最大历史电影ID列表长度\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        uid = torch.tensor(self.features[idx][0])\n",
    "        movie_id = torch.tensor(self.features[idx][1])\n",
    "        user_gender = torch.tensor(self.features[idx][2])\n",
    "        user_age = torch.tensor(self.features[idx][3])\n",
    "        user_job = torch.tensor(self.features[idx][4])\n",
    "        movie_titles = torch.tensor(self.features[idx][6])\n",
    "        movie_categories = torch.tensor(self.features[idx][7])\n",
    "        history_movie_ids = torch.tensor(self.features[idx][8])\n",
    "\n",
    "        # 这里一定要对history_movie_ids进行填充操作，否则会出现报错（需要保证传入的长度都是一致的）\n",
    "        # 填充操作\n",
    "        padding_len = self.max_hist_len - len(history_movie_ids)\n",
    "        if padding_len > 0:\n",
    "            padding = torch.zeros(padding_len, dtype=torch.long)\n",
    "            history_movie_ids = torch.cat((history_movie_ids, padding), dim=0)\n",
    "        targets = torch.tensor(self.targets[idx]).float()\n",
    "        return uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, history_movie_ids, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备{device}\")\n",
    "\n",
    "class RankModel:\n",
    "    def __init__(self, uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num, max_hist_num):\n",
    "        \"\"\"初始化DIN排序模型\"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # 这里假设DINModel已经定义\n",
    "        self.model = DINModel(uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num, max_hist_len).to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters())\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def train(self, train_loader, num_epochs=5):\n",
    "        \"\"\"训练模型\n",
    "        Args:\n",
    "            train_features: 训练集特征\n",
    "            train_targets: 训练集标签\n",
    "        \"\"\"\n",
    "        print(\"开始训练DIN排序模型...\")\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            for batch_i, (uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, ratings, history_movie_ids) in enumerate(train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                uid = uid.to(device)\n",
    "                user_gender = user_gender.to(device)\n",
    "                user_age = user_age.to(device)\n",
    "                user_job = user_job.to(device)\n",
    "                movie_id = movie_id.to(device)\n",
    "                movie_categories = movie_categories.to(device)\n",
    "                movie_titles = movie_titles.to(device)\n",
    "                history_movie_ids = history_movie_ids.to(device)\n",
    "                ratings = ratings.to(device)\n",
    "\n",
    "                # 前向传播\n",
    "                outputs = self.model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, history_movie_ids)\n",
    "                loss = self.criterion(outputs, ratings)\n",
    "\n",
    "                # 反向传播和优化\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if (batch_i + 1) % 100 == 0:\n",
    "                    print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{batch_i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "        print(\"训练完成！\")\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        \"\"\"评估模型\n",
    "        Args:\n",
    "            test_loader: 测试集的DataLoader\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for batch_i, (uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, ratings, history_movie_ids) in enumerate(test_loader):\n",
    "                uid = torch.LongTensor(uid).to(self.device)\n",
    "                user_gender = torch.LongTensor(user_gender).to(self.device)\n",
    "                user_age = torch.LongTensor(user_age).to(self.device)\n",
    "                user_job = torch.LongTensor(user_job).to(self.device)\n",
    "                movie_id = torch.LongTensor(movie_id).to(self.device)\n",
    "                movie_categories = torch.LongTensor(movie_categories).to(self.device)\n",
    "                movie_titles = torch.LongTensor(movie_titles).to(self.device)\n",
    "                targets = torch.FloatTensor(ratings).to(self.device)\n",
    "                history_movie_ids=torch.LongTensor(history_movie_ids).to(self.device)\n",
    "                predictions = self.model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles)\n",
    "                all_predictions.extend(predictions.cpu().numpy().flatten())\n",
    "                all_targets.extend(targets.cpu().numpy().flatten())\n",
    "\n",
    "        mse = mean_squared_error(all_targets, all_predictions)\n",
    "        mae = mean_absolute_error(all_targets, all_predictions)\n",
    "        print(f\"测试集MSE: {mse:.4f}\")\n",
    "        print(f\"测试集MAE: {mae:.4f}\")\n",
    "\n",
    "    def predict(self, features: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"预测评分\n",
    "        Args:\n",
    "            features: 待预测特征\n",
    "        Returns:\n",
    "            预测的评分\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            uid = torch.LongTensor(features[:, 0]).to(self.device)\n",
    "            user_gender = torch.LongTensor(features[:, 2]).to(self.device)\n",
    "            user_age = torch.LongTensor(features[:, 3]).to(self.device)\n",
    "            user_job = torch.LongTensor(features[:, 4]).to(self.device)\n",
    "            movie_id = torch.LongTensor(features[:, 1]).to(self.device)\n",
    "            movie_categories = torch.LongTensor(features[:, 7]).to(self.device)\n",
    "            movie_titles = torch.LongTensor(features[:, 6]).to(self.device)\n",
    "            history_movie_ids = torch.LongTensor(features[:, 8]).to(self.device)\n",
    "\n",
    "            predictions = self.model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, history_movie_ids)\n",
    "            return predictions.cpu().numpy()\n",
    "\n",
    "    def get_recommendations(self, user_features: np.ndarray, recall_movie_features: np.ndarray, top_k: int = 10) -> List[Tuple[int, float]]:\n",
    "        \"\"\"获取推荐电影列表\n",
    "        Args:\n",
    "            user_features: 用户特征\n",
    "            recall_movie_features: 召回的候选电影特征\n",
    "            top_k: 推荐电影数量\n",
    "        Returns:\n",
    "            推荐电影列表，每个元素为(电影ID, 预测评分)\n",
    "        \"\"\"\n",
    "        predictions = self.predict(recall_movie_features)\n",
    "        movie_scores = list(enumerate(predictions))\n",
    "        movie_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return movie_scores[:top_k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_targets, test_features, test_targets=pickle.load(open('./data/split_dataset.p', 'rb'))\n",
    "title2int, title_count, title_set, genres2int, genres_map, features_pd, targets_pd, features, targets_values, ratings_df, users_df, movies_df, data = pickle.load(open('./data/preprocess.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4835, 130, 3852, 2242, 1296, 4153, 3512, 3512...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4809, 4472, 2242, 3869, 1291, 3512, 3512, 351...</td>\n",
       "      <td>[11, 15, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4394, 1320, 1007, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[1951, 4696, 3512, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[722, 932, 973, 3512, 3512, 3512, 3512, 3512, ...</td>\n",
       "      <td>[11, 15, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  gender  age  occupation zip_code  \\\n",
       "0        1      1193       5       1    0          10    48067   \n",
       "1        1       661       3       1    0          10    48067   \n",
       "2        1       914       3       1    0          10    48067   \n",
       "3        1      3408       4       1    0          10    48067   \n",
       "4        1      2355       5       1    0          10    48067   \n",
       "\n",
       "                                               title  \\\n",
       "0  [4835, 130, 3852, 2242, 1296, 4153, 3512, 3512...   \n",
       "1  [4809, 4472, 2242, 3869, 1291, 3512, 3512, 351...   \n",
       "2  [4394, 1320, 1007, 3512, 3512, 3512, 3512, 351...   \n",
       "3  [1951, 4696, 3512, 3512, 3512, 3512, 3512, 351...   \n",
       "4  [722, 932, 973, 3512, 3512, 3512, 3512, 3512, ...   \n",
       "\n",
       "                                              genres  \n",
       "0  [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "1  [11, 15, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...  \n",
       "2  [0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "3  [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "4  [11, 15, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_ids = data.groupby('user_id')['movie_id'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[1357, 3068, 1537, 647, 2194, 648, 2268, 2628,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[3421, 1641, 648, 1394, 3534, 104, 2735, 1210,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[3468, 1210, 2951, 1214, 1036, 260, 2028, 480,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[2987, 2333, 1175, 39, 288, 2337, 1535, 1392, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6036</td>\n",
       "      <td>[571, 574, 2053, 2054, 2058, 588, 589, 4, 3005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6037</td>\n",
       "      <td>[589, 3006, 1407, 2064, 2065, 593, 3015, 903, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6038</td>\n",
       "      <td>[1419, 920, 3088, 232, 1136, 1148, 1183, 2146,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6039</td>\n",
       "      <td>[588, 2067, 1416, 3022, 3028, 2080, 2083, 2087...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6040</td>\n",
       "      <td>[573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                                           movie_id\n",
       "0           1  [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...\n",
       "1           2  [1357, 3068, 1537, 647, 2194, 648, 2268, 2628,...\n",
       "2           3  [3421, 1641, 648, 1394, 3534, 104, 2735, 1210,...\n",
       "3           4  [3468, 1210, 2951, 1214, 1036, 260, 2028, 480,...\n",
       "4           5  [2987, 2333, 1175, 39, 288, 2337, 1535, 1392, ...\n",
       "...       ...                                                ...\n",
       "6035     6036  [571, 574, 2053, 2054, 2058, 588, 589, 4, 3005...\n",
       "6036     6037  [589, 3006, 1407, 2064, 2065, 593, 3015, 903, ...\n",
       "6037     6038  [1419, 920, 3088, 232, 1136, 1148, 1183, 2146,...\n",
       "6038     6039  [588, 2067, 1416, 3022, 3028, 2080, 2083, 2087...\n",
       "6039     6040  [573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...\n",
       "\n",
       "[6040 rows x 2 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_movie_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在data后增加一列，用来记录用户的历史观看的电影ID\n",
    "new_data = pd.merge(data, user_movie_ids, on='user_id', how='left')\n",
    "\n",
    "# 修改列名\n",
    "new_data=new_data.rename(columns={'movie_id_y':'history_movie_ids', 'movie_id_x': 'movie_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'movie_id', 'rating', 'gender', 'age', 'occupation',\n",
       "       'zip_code', 'title', 'genres', 'history_movie_ids'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始划分训练集和测试集...\n",
      "最长的历史电影ID数量为: 2314\n",
      "训练集大小: 800167\n",
      "测试集大小: 200042\n"
     ]
    }
   ],
   "source": [
    "# 从data中划分训练集和测试集\n",
    "print(\"开始划分训练集和测试集...\")\n",
    "\n",
    "# 将数据转换为numpy数组\n",
    "features = np.array(new_data[['user_id', 'movie_id', 'gender', 'age', 'occupation', 'zip_code', 'title', 'genres', 'history_movie_ids']].values)\n",
    "targets = np.array(new_data['rating'].values)\n",
    "\n",
    "max_hist_len = max(len(feature[8]) for feature in features)\n",
    "print(\"最长的历史电影ID数量为:\", max_hist_len)\n",
    "\n",
    "\n",
    "# 使用train_test_split划分训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_targets, test_targets = train_test_split(\n",
    "    features, targets, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {len(train_features)}\")\n",
    "print(f\"测试集大小: {len(test_features)}\")\n",
    "\n",
    "train_dataset=MovieDataset(train_features, train_targets)\n",
    "test_dataset=MovieDataset(test_features, test_targets)\n",
    "train_loader=DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader=DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练模型...\n",
      "开始训练DIN排序模型...\n",
      "电影ID维度: torch.Size([32, 16])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m开始训练模型...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mrank_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 评估模型\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m开始评估模型...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[124], line 41\u001b[0m, in \u001b[0;36mRankModel.train\u001b[0;34m(self, train_loader, num_epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m ratings \u001b[38;5;241m=\u001b[39m ratings\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 前向传播\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_gender\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_age\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_job\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_categories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovie_titles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory_movie_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, ratings)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# 反向传播和优化\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[122], line 64\u001b[0m, in \u001b[0;36mDINModel.forward\u001b[0;34m(self, uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, history_movie_ids)\u001b[0m\n\u001b[1;32m     61\u001b[0m movie_titles_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmovie_title_embedding(movie_titles)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# 嵌入历史电影ID特征\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m hist_movie_embed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmovie_id_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhistory_movie_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m历史电影ID维度:\u001b[39m\u001b[38;5;124m'\u001b[39m, hist_movie_embed\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# 注意力机制处理历史交互\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got torch.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "embed_dim = 32\n",
    "# 用户 ID 个数\n",
    "uid_num = max(features.take(0, 1)) + 1\n",
    "# 性别个数\n",
    "gender_num = max(features.take(2, 1)) + 1\n",
    "# 年龄类别个数\n",
    "age_num = max(features.take(3, 1)) + 1\n",
    "# 职业个数\n",
    "job_num = max(features.take(4, 1)) + 1\n",
    "\n",
    "# 电影 ID 个数\n",
    "mid_num = max(features.take(1, 1)) + 1\n",
    "# 电影类型个数\n",
    "movie_category_num = max(genres2int.values()) + 1\n",
    "# 电影名单词个数\n",
    "movie_title_num = len(title_set)\n",
    "\n",
    "# 初始化排序模型\n",
    "rank_model = RankModel(uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num, max_hist_len)\n",
    "\n",
    "# 训练模型\n",
    "print(\"开始训练模型...\")\n",
    "rank_model.train(train_loader)\n",
    "\n",
    "# 评估模型\n",
    "print(\"开始评估模型...\")\n",
    "rank_model.evaluate(test_features, test_targets)\n",
    "\n",
    "# 保存模型\n",
    "save_dir = os.path.join(os.getcwd(), \"model_save\")\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# 获取当前日期作为模型文件名的一部分\n",
    "from datetime import datetime\n",
    "today = datetime.today()\n",
    "formatted_date = today.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 评估模型\n",
    "print(\"开始评估模型...\")\n",
    "rank_model.evaluate(test_features, test_targets)\n",
    "\n",
    "# 保存模型\n",
    "save_dir = os.path.join(os.getcwd(), \"model_save\")\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# 获取当前日期作为模型文件名的一部分\n",
    "from datetime import datetime\n",
    "today = datetime.today()\n",
    "formatted_date = today.strftime('%Y%m%d')\n",
    "\n",
    "# 保存模型\n",
    "model_path = os.path.join(save_dir, f\"rank_model_{formatted_date}.pkl\")\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(rank_model, f)\n",
    "print(f'模型已保存到: {model_path}')\n",
    "\n",
    "# 测试推荐功能\n",
    "print(\"\\n测试推荐功能:\")\n",
    "# 随机选择一个用户\n",
    "test_user_idx = np.random.randint(0, len(test_features))\n",
    "test_user_features = test_features[test_user_idx:test_user_idx+1]\n",
    "\n",
    "# 首先使用召回模型获取候选集\n",
    "with torch.no_grad():\n",
    "    recall_candidates = recall_model.get_recall_candidates(test_user_features, top_k=100)\n",
    "\n",
    "# 获取召回候选集的特征\n",
    "recall_movie_features = test_features[recall_candidates]\n",
    "\n",
    "# 使用排序模型对召回结果进行排序\n",
    "recommendations = rank_model.get_recommendations(test_user_features, recall_movie_features, top_k=5)\n",
    "print(f\"为用户推荐的Top5电影ID及预测评分:\")\n",
    "for movie_id, score in recommendations:\n",
    "    print(f\"电影ID: {movie_id}, 预测评分: {score:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
