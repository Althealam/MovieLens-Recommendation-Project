{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "# 1. 加载数据\n",
    "movies = pd.read_csv('./data/ml-1m/movies.csv')\n",
    "ratings = pd.read_csv('./data/ml-1m/ratings.csv')\n",
    "users = pd.read_csv('./data/ml-1m/users.csv')\n",
    "\n",
    "# 2. 将评分转换为隐式反馈(假设rating>=4为正样本)\n",
    "ratings['label'] = (ratings['rating'] >= 4).astype(int)\n",
    "\n",
    "# 3. 处理电影类型特征(多值特征)\n",
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "genre_list = list(set(g for genres in movies['genres'] for g in genres))\n",
    "for genre in genre_list:\n",
    "    movies[f'genre_{genre}'] = movies['genres'].apply(lambda x: int(genre in x))\n",
    "\n",
    "# 4. 编码分类特征\n",
    "user_features = ['user_id', 'gender', 'age', 'occupation']\n",
    "movie_features = ['movie_id'] + [f'genre_{g}' for g in genre_list]\n",
    "\n",
    "# 5. 构建用户历史行为序列\n",
    "# 按时间戳排序\n",
    "ratings = ratings.sort_values(['user_id', 'timestamp'])\n",
    "# 为每个用户保留最近的50次行为作为历史序列\n",
    "user_hist = ratings.groupby('user_id').tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建DIN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_din_model(num_users, num_movies, genre_size, max_seq_length=50):\n",
    "    # 输入层\n",
    "    # 用户特征\n",
    "    user_id_input = Input(shape=(1,), name='user_id')\n",
    "    gender_input = Input(shape=(1,), name='gender')\n",
    "    age_input = Input(shape=(1,), name='age')\n",
    "    occupation_input = Input(shape=(1,), name='occupation')\n",
    "    \n",
    "    # 电影特征\n",
    "    movie_id_input = Input(shape=(1,), name='movie_id')\n",
    "    movie_genres_input = Input(shape=(genre_size,), name='movie_genres')\n",
    "    \n",
    "    # 历史电影特征\n",
    "    hist_movie_ids_input = Input(shape=(max_seq_length,), name='hist_movie_ids')\n",
    "    hist_movie_genres_input = Input(shape=(max_seq_length, genre_size), name='hist_movie_genres')\n",
    "    \n",
    "    # 嵌入层\n",
    "    user_id_embed = Embedding(num_users, 16)(user_id_input)\n",
    "    gender_embed = Embedding(2, 4)(gender_input)\n",
    "    age_embed = Embedding(7, 4)(age_input)  # age是1-7的类别\n",
    "    occupation_embed = Embedding(21, 4)(occupation_input)  # 0-20共21个职业\n",
    "    \n",
    "    movie_id_embed = Embedding(num_movies, 16)(movie_id_input)\n",
    "    hist_movie_ids_embed = Embedding(num_movies, 16)(hist_movie_ids_input)\n",
    "    \n",
    "    # 拼接用户特征\n",
    "    user_embed = Concatenate()([\n",
    "        Flatten()(user_id_embed),\n",
    "        Flatten()(gender_embed),\n",
    "        Flatten()(age_embed),\n",
    "        Flatten()(occupation_embed)\n",
    "    ])\n",
    "    \n",
    "    # 候选物品特征\n",
    "    candidate_embed = Concatenate()([\n",
    "        Flatten()(movie_id_embed),\n",
    "        Flatten()(movie_genres_input)\n",
    "    ])\n",
    "    \n",
    "    # 历史行为序列处理\n",
    "    hist_movie_embeds = TimeDistributed(\n",
    "        Concatenate()([\n",
    "            Flatten()(hist_movie_ids_embed),\n",
    "            Flatten()(hist_movie_genres_input)\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    # 注意力机制\n",
    "    attention_output = AttentionLayer()([candidate_embed, hist_movie_embeds])\n",
    "    \n",
    "    # 深度网络\n",
    "    deep_input = Concatenate()([user_embed, candidate_embed, attention_output])\n",
    "    dnn_output = Dense(128, activation='relu')(deep_input)\n",
    "    dnn_output = Dense(64, activation='relu')(dnn_output)\n",
    "    \n",
    "    # 输出层\n",
    "    output = Dense(1, activation='sigmoid')(dnn_output)\n",
    "    \n",
    "    model = Model(inputs=[\n",
    "        user_id_input, gender_input, age_input, occupation_input,\n",
    "        movie_id_input, movie_genres_input,\n",
    "        hist_movie_ids_input, hist_movie_genres_input\n",
    "    ], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意力层\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(\n",
    "            name='attention_weight',\n",
    "            shape=(input_shape[0][-1], input_shape[1][-1]),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            name='attention_bias',\n",
    "            shape=(input_shape[1][1],),\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # query: candidate item, key: history items\n",
    "        query, keys = inputs\n",
    "        # 计算注意力得分\n",
    "        query = tf.expand_dims(query, 1)  # [B, 1, D]\n",
    "        scores = tf.matmul(keys, tf.matmul(query, self.W) + self.b)  # [B, T, 1]\n",
    "        scores = tf.nn.softmax(scores, axis=1)\n",
    "        # 加权求和\n",
    "        output = tf.reduce_sum(scores * keys, axis=1)  # [B, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据管道构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建训练样本\n",
    "def generate_samples(ratings, user_hist, movies, genre_list, max_seq_length=50):\n",
    "    samples = []\n",
    "    for _, row in ratings.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        movie_id = row['movie_id']\n",
    "        label = row['label']\n",
    "        \n",
    "        # 获取用户特征\n",
    "        user_data = users[users['user_id'] == user_id].iloc[0]\n",
    "        \n",
    "        # 获取候选物品特征\n",
    "        movie_data = movies[movies['movie_id'] == movie_id].iloc[0]\n",
    "        movie_genres = [int(genre in movie_data['genres']) for genre in genre_list]\n",
    "        \n",
    "        # 获取用户历史行为序列\n",
    "        hist = user_hist[user_hist['user_id'] == user_id]\n",
    "        hist_movie_ids = hist['movie_id'].values[-max_seq_length:]\n",
    "        hist_movie_genres = []\n",
    "        \n",
    "        for m_id in hist_movie_ids:\n",
    "            m_data = movies[movies['movie_id'] == m_id].iloc[0]\n",
    "            hist_movie_genres.append([int(genre in m_data['genres']) for genre in genre_list])\n",
    "        \n",
    "        # 填充或截断序列\n",
    "        if len(hist_movie_ids) < max_seq_length:\n",
    "            pad_len = max_seq_length - len(hist_movie_ids)\n",
    "            hist_movie_ids = np.pad(hist_movie_ids, (0, pad_len), 'constant')\n",
    "            hist_movie_genres += [[0]*len(genre_list)] * pad_len\n",
    "        \n",
    "        sample = {\n",
    "            'user_id': user_id,\n",
    "            'gender': 0 if user_data['gender'] == 'F' else 1,\n",
    "            'age': user_data['age'],\n",
    "            'occupation': user_data['occupation'],\n",
    "            'movie_id': movie_id,\n",
    "            'movie_genres': movie_genres,\n",
    "            'hist_movie_ids': hist_movie_ids,\n",
    "            'hist_movie_genres': hist_movie_genres,\n",
    "            'label': label\n",
    "        }\n",
    "        samples.append(sample)\n",
    "    \n",
    "    return pd.DataFrame(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建tensorflow dataset\n",
    "def create_dataset(df, batch_size=32):\n",
    "    def generator():\n",
    "        for _, row in df.iterrows():\n",
    "            yield (\n",
    "                {\n",
    "                    'user_id': np.array([row['user_id']]),\n",
    "                    'gender': np.array([row['gender']]),\n",
    "                    'age': np.array([row['age']]),\n",
    "                    'occupation': np.array([row['occupation']]),\n",
    "                    'movie_id': np.array([row['movie_id']]),\n",
    "                    'movie_genres': np.array(row['movie_genres']),\n",
    "                    'hist_movie_ids': np.array(row['hist_movie_ids']),\n",
    "                    'hist_movie_genres': np.array(row['hist_movie_genres'])\n",
    "                },\n",
    "                np.array([row['label']])\n",
    "            )\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_types=(\n",
    "            {\n",
    "                'user_id': tf.int32,\n",
    "                'gender': tf.int32,\n",
    "                'age': tf.int32,\n",
    "                'occupation': tf.int32,\n",
    "                'movie_id': tf.int32,\n",
    "                'movie_genres': tf.float32,\n",
    "                'hist_movie_ids': tf.int32,\n",
    "                'hist_movie_genres': tf.float32\n",
    "            },\n",
    "            tf.float32\n",
    "        ),\n",
    "        output_shapes=(\n",
    "            {\n",
    "                'user_id': (1,),\n",
    "                'gender': (1,),\n",
    "                'age': (1,),\n",
    "                'occupation': (1,),\n",
    "                'movie_id': (1,),\n",
    "                'movie_genres': (len(genre_list),),\n",
    "                'hist_movie_ids': (max_seq_length,),\n",
    "                'hist_movie_genres': (max_seq_length, len(genre_list))\n",
    "            },\n",
    "            (1,)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按时间戳排序后，取前80%作为训练，后20%作为验证\n",
    "ratings = ratings.sort_values('timestamp')\n",
    "train_size = int(len(ratings) * 0.8)\n",
    "\n",
    "train_ratings = ratings.iloc[:train_size]\n",
    "print(\"训练集大小:\", len(train_ratings))\n",
    "val_ratings = ratings.iloc[train_size:]\n",
    "print(\"验证集大小:\", len(val_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gl/ktsnc2lj2l50gvkwynrph3k40000gn/T/ipykernel_96229/3572410716.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;31m# 参数设置\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/gl/ktsnc2lj2l50gvkwynrph3k40000gn/T/ipykernel_96229/3211431153.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(ratings, user_hist, movies, genre_list, max_seq_length)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mhist_movie_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movie_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mhist_movie_genres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhist_movie_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mm_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'movie_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mm_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mhist_movie_genres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenre\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genres'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgenre\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenre_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# 填充或截断序列\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4089\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4091\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4092\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4093\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4095\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4096\u001b[0m         \u001b[0;31m# We interpret tuples as collections only for non-MultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4149\u001b[0m         \u001b[0mFor\u001b[0m \u001b[0mSeries\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpublic\u001b[0m \u001b[0mtake\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0mnever\u001b[0m \u001b[0msets\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m_is_copy\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4151\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \"\"\"\n\u001b[0;32m-> 4153\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4156\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4131\u001b[0m             )\n\u001b[1;32m   4132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4133\u001b[0m         new_data = self._mgr.take(\n\u001b[1;32m   4134\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4135\u001b[0;31m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4136\u001b[0m             \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4137\u001b[0m         )\n\u001b[1;32m   4138\u001b[0m         return self._constructor_from_mgr(new_data, axes=new_data.axes).__finalize__(\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;34m\"\"\"Map the axis to the block_manager axis.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_LEN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# i.e. DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 参数设置\n",
    "max_seq_length = 50\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "\n",
    "# 准备数据\n",
    "train_samples = generate_samples(train_ratings, user_hist, movies, genre_list, max_seq_length)\n",
    "val_samples = generate_samples(val_ratings, user_hist, movies, genre_list, max_seq_length)\n",
    "\n",
    "train_dataset = create_dataset(train_samples, batch_size)\n",
    "val_dataset = create_dataset(val_samples, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 构建模型\n",
    "num_users = users['user_id'].nunique()\n",
    "num_movies = movies['movie_id'].nunique()\n",
    "genre_size = len(genre_list)\n",
    "\n",
    "model = build_din_model(num_users, num_movies, genre_size, max_seq_length)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC()]\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
