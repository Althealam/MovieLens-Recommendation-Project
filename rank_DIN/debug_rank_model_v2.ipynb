{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "# 1. 加载数据\n",
    "movies = pd.read_csv('/Users/bytedance/Desktop/MovieLens-Recommendation-System/data/ml-1m/movies.csv')\n",
    "ratings = pd.read_csv('/Users/bytedance/Desktop/MovieLens-Recommendation-System/data/ml-1m/ratings.csv')\n",
    "users = pd.read_csv('/Users/bytedance/Desktop/MovieLens-Recommendation-System/data/ml-1m/users.csv')\n",
    "\n",
    "# 2. 将评分转换为隐式反馈(假设rating>=4为正样本)\n",
    "ratings['label'] = (ratings['rating'] >= 4).astype(int)\n",
    "\n",
    "# 3. 处理电影类型特征(多值特征)\n",
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "genre_list = list(set(g for genres in movies['genres'] for g in genres))\n",
    "for genre in genre_list:\n",
    "    movies[f'genre_{genre}'] = movies['genres'].apply(lambda x: int(genre in x))\n",
    "\n",
    "# 4. 编码分类特征\n",
    "user_features = ['user_id', 'gender', 'age', 'occupation']\n",
    "movie_features = ['movie_id'] + [f'genre_{g}' for g in genre_list]\n",
    "\n",
    "# 5. 构建用户历史行为序列\n",
    "# 按时间戳排序\n",
    "ratings = ratings.sort_values(['user_id', 'timestamp'])\n",
    "# 为每个用户保留最近的50次行为作为历史序列\n",
    "user_hist = ratings.groupby('user_id').tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建DIN模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_din_model(num_users, num_movies, genre_size, max_seq_length=50):\n",
    "    # 输入层\n",
    "    # 用户特征\n",
    "    user_id_input = Input(shape=(1,), name='user_id')\n",
    "    gender_input = Input(shape=(1,), name='gender')\n",
    "    age_input = Input(shape=(1,), name='age')\n",
    "    occupation_input = Input(shape=(1,), name='occupation')\n",
    "    \n",
    "    # 电影特征\n",
    "    movie_id_input = Input(shape=(1,), name='movie_id')\n",
    "    movie_genres_input = Input(shape=(genre_size,), name='movie_genres')\n",
    "    \n",
    "    # 历史电影特征\n",
    "    hist_movie_ids_input = Input(shape=(max_seq_length,), name='hist_movie_ids')\n",
    "    hist_movie_genres_input = Input(shape=(max_seq_length, genre_size), name='hist_movie_genres')\n",
    "    \n",
    "    # 嵌入层\n",
    "    user_id_embed = Embedding(num_users, 16)(user_id_input)\n",
    "    gender_embed = Embedding(2, 4)(gender_input)\n",
    "    age_embed = Embedding(7, 4)(age_input)  # age是1-7的类别\n",
    "    occupation_embed = Embedding(21, 4)(occupation_input)  # 0-20共21个职业\n",
    "    \n",
    "    movie_id_embed = Embedding(num_movies, 16)(movie_id_input)\n",
    "    hist_movie_ids_embed = Embedding(num_movies, 16)(hist_movie_ids_input)\n",
    "    \n",
    "    # 拼接用户特征\n",
    "    user_embed = Concatenate()([\n",
    "        Flatten()(user_id_embed),\n",
    "        Flatten()(gender_embed),\n",
    "        Flatten()(age_embed),\n",
    "        Flatten()(occupation_embed)\n",
    "    ])\n",
    "    \n",
    "    # 候选物品特征\n",
    "    candidate_embed = Concatenate()([\n",
    "        Flatten()(movie_id_embed),\n",
    "        Flatten()(movie_genres_input)\n",
    "    ])\n",
    "    \n",
    "    # 历史行为序列处理\n",
    "    hist_movie_embeds = TimeDistributed(\n",
    "        Concatenate()([\n",
    "            Flatten()(hist_movie_ids_embed),\n",
    "            Flatten()(hist_movie_genres_input)\n",
    "        ])\n",
    "    )\n",
    "    \n",
    "    # 注意力机制\n",
    "    attention_output = AttentionLayer()([candidate_embed, hist_movie_embeds])\n",
    "    \n",
    "    # 深度网络\n",
    "    deep_input = Concatenate()([user_embed, candidate_embed, attention_output])\n",
    "    dnn_output = Dense(128, activation='relu')(deep_input)\n",
    "    dnn_output = Dense(64, activation='relu')(dnn_output)\n",
    "    \n",
    "    # 输出层\n",
    "    output = Dense(1, activation='sigmoid')(dnn_output)\n",
    "    \n",
    "    model = Model(inputs=[\n",
    "        user_id_input, gender_input, age_input, occupation_input,\n",
    "        movie_id_input, movie_genres_input,\n",
    "        hist_movie_ids_input, hist_movie_genres_input\n",
    "    ], outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意力层\n",
    "class AttentionLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(\n",
    "            name='attention_weight',\n",
    "            shape=(input_shape[0][-1], input_shape[1][-1]),\n",
    "            initializer='random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            name='attention_bias',\n",
    "            shape=(input_shape[1][1],),\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # query: candidate item, key: history items\n",
    "        query, keys = inputs\n",
    "        # 计算注意力得分\n",
    "        query = tf.expand_dims(query, 1)  # [B, 1, D]\n",
    "        scores = tf.matmul(keys, tf.matmul(query, self.W) + self.b)  # [B, T, 1]\n",
    "        scores = tf.nn.softmax(scores, axis=1)\n",
    "        # 加权求和\n",
    "        output = tf.reduce_sum(scores * keys, axis=1)  # [B, D]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据管道构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建训练样本\n",
    "def generate_samples(ratings, user_hist, movies, genre_list, max_seq_length=50):\n",
    "    samples = []\n",
    "    for _, row in ratings.iterrows():\n",
    "        user_id = row['user_id']\n",
    "        movie_id = row['movie_id']\n",
    "        label = row['label']\n",
    "        \n",
    "        # 获取用户特征\n",
    "        user_data = users[users['user_id'] == user_id].iloc[0]\n",
    "        \n",
    "        # 获取候选物品特征\n",
    "        movie_data = movies[movies['movie_id'] == movie_id].iloc[0]\n",
    "        movie_genres = [int(genre in movie_data['genres']) for genre in genre_list]\n",
    "        \n",
    "        # 获取用户历史行为序列\n",
    "        hist = user_hist[user_hist['user_id'] == user_id]\n",
    "        hist_movie_ids = hist['movie_id'].values[-max_seq_length:]\n",
    "        hist_movie_genres = []\n",
    "        \n",
    "        for m_id in hist_movie_ids:\n",
    "            m_data = movies[movies['movie_id'] == m_id].iloc[0]\n",
    "            hist_movie_genres.append([int(genre in m_data['genres']) for genre in genre_list])\n",
    "        \n",
    "        # 填充或截断序列\n",
    "        if len(hist_movie_ids) < max_seq_length:\n",
    "            pad_len = max_seq_length - len(hist_movie_ids)\n",
    "            hist_movie_ids = np.pad(hist_movie_ids, (0, pad_len), 'constant')\n",
    "            hist_movie_genres += [[0]*len(genre_list)] * pad_len\n",
    "        \n",
    "        sample = {\n",
    "            'user_id': user_id,\n",
    "            'gender': 0 if user_data['gender'] == 'F' else 1,\n",
    "            'age': user_data['age'],\n",
    "            'occupation': user_data['occupation'],\n",
    "            'movie_id': movie_id,\n",
    "            'movie_genres': movie_genres,\n",
    "            'hist_movie_ids': hist_movie_ids,\n",
    "            'hist_movie_genres': hist_movie_genres,\n",
    "            'label': label\n",
    "        }\n",
    "        samples.append(sample)\n",
    "    \n",
    "    return pd.DataFrame(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建tensorflow dataset\n",
    "def create_dataset(df, batch_size=32):\n",
    "    def generator():\n",
    "        for _, row in df.iterrows():\n",
    "            yield (\n",
    "                {\n",
    "                    'user_id': np.array([row['user_id']]),\n",
    "                    'gender': np.array([row['gender']]),\n",
    "                    'age': np.array([row['age']]),\n",
    "                    'occupation': np.array([row['occupation']]),\n",
    "                    'movie_id': np.array([row['movie_id']]),\n",
    "                    'movie_genres': np.array(row['movie_genres']),\n",
    "                    'hist_movie_ids': np.array(row['hist_movie_ids']),\n",
    "                    'hist_movie_genres': np.array(row['hist_movie_genres'])\n",
    "                },\n",
    "                np.array([row['label']])\n",
    "            )\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator,\n",
    "        output_types=(\n",
    "            {\n",
    "                'user_id': tf.int32,\n",
    "                'gender': tf.int32,\n",
    "                'age': tf.int32,\n",
    "                'occupation': tf.int32,\n",
    "                'movie_id': tf.int32,\n",
    "                'movie_genres': tf.float32,\n",
    "                'hist_movie_ids': tf.int32,\n",
    "                'hist_movie_genres': tf.float32\n",
    "            },\n",
    "            tf.float32\n",
    "        ),\n",
    "        output_shapes=(\n",
    "            {\n",
    "                'user_id': (1,),\n",
    "                'gender': (1,),\n",
    "                'age': (1,),\n",
    "                'occupation': (1,),\n",
    "                'movie_id': (1,),\n",
    "                'movie_genres': (len(genre_list),),\n",
    "                'hist_movie_ids': (max_seq_length,),\n",
    "                'hist_movie_genres': (max_seq_length, len(genre_list))\n",
    "            },\n",
    "            (1,)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 800167\n",
      "验证集大小: 200042\n"
     ]
    }
   ],
   "source": [
    "# 按时间戳排序后，取前80%作为训练，后20%作为验证\n",
    "ratings = ratings.sort_values('timestamp')\n",
    "train_size = int(len(ratings) * 0.8)\n",
    "\n",
    "train_ratings = ratings.iloc[:train_size]\n",
    "print(\"训练集大小:\", len(train_ratings))\n",
    "val_ratings = ratings.iloc[train_size:]\n",
    "print(\"验证集大小:\", len(val_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# 准备数据\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m train_samples \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ratings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_hist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmovies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenre_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m val_samples \u001b[38;5;241m=\u001b[39m generate_samples(val_ratings, user_hist, movies, genre_list, max_seq_length)\n\u001b[1;32m     10\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m create_dataset(train_samples, batch_size)\n",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m, in \u001b[0;36mgenerate_samples\u001b[0;34m(ratings, user_hist, movies, genre_list, max_seq_length)\u001b[0m\n\u001b[1;32m     19\u001b[0m hist_movie_genres \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m_id \u001b[38;5;129;01min\u001b[39;00m hist_movie_ids:\n\u001b[0;32m---> 22\u001b[0m     m_data \u001b[38;5;241m=\u001b[39m \u001b[43mmovies\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmovies\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmovie_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mm_id\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     23\u001b[0m     hist_movie_genres\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mint\u001b[39m(genre \u001b[38;5;129;01min\u001b[39;00m m_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m genre \u001b[38;5;129;01min\u001b[39;00m genre_list])\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 填充或截断序列\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4093\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[1;32m   4092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 4093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4095\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[1;32m   4096\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[1;32m   4097\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4155\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   4154\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 4155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_with_is_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:4153\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   4143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   4144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4145\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   4146\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4151\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   4152\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4154\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   4155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4131\u001b[0m     )\n\u001b[0;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4135\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_block_manager_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4140\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/managers.py:687\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    681\u001b[0m         indexer,\n\u001b[1;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    689\u001b[0m             indexer,\n\u001b[1;32m    690\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    691\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    692\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    693\u001b[0m             ),\n\u001b[1;32m    694\u001b[0m         )\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    696\u001b[0m     ]\n\u001b[1;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/managers.py:688\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    681\u001b[0m         indexer,\n\u001b[1;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 688\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    696\u001b[0m     ]\n\u001b[1;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/internals/blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/array_algos/take.py:133\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    131\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m ensure_platform_int(indexer)\n\u001b[0;32m--> 133\u001b[0m dtype, fill_value, mask_info \u001b[38;5;241m=\u001b[39m \u001b[43m_take_preprocess_indexer_and_fill_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m flip_order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/array_algos/take.py:585\u001b[0m, in \u001b[0;36m_take_preprocess_indexer_and_fill_value\u001b[0;34m(arr, indexer, fill_value, allow_fill, mask)\u001b[0m\n\u001b[1;32m    583\u001b[0m     needs_masking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 585\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mindexer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    586\u001b[0m     needs_masking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(mask\u001b[38;5;241m.\u001b[39many())\n\u001b[1;32m    587\u001b[0m mask_info \u001b[38;5;241m=\u001b[39m mask, needs_masking\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 参数设置\n",
    "max_seq_length = 50\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "\n",
    "# 准备数据\n",
    "train_samples = generate_samples(train_ratings, user_hist, movies, genre_list, max_seq_length)\n",
    "val_samples = generate_samples(val_ratings, user_hist, movies, genre_list, max_seq_length)\n",
    "\n",
    "train_dataset = create_dataset(train_samples, batch_size)\n",
    "val_dataset = create_dataset(val_samples, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 构建模型\n",
    "num_users = users['user_id'].nunique()\n",
    "num_movies = movies['movie_id'].nunique()\n",
    "genre_size = len(genre_list)\n",
    "\n",
    "model = build_din_model(num_users, num_movies, genre_size, max_seq_length)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC()]\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
