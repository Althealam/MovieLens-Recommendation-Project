{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from typing import List, Tuple\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dice(nn.Module):\n",
    "    def __init__(self, num_features, epsilon=1e-8):\n",
    "        super(Dice, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(num_features, affine=False)\n",
    "        self.alpha = nn.Parameter(torch.zeros(num_features))\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_normed = self.bn(x)\n",
    "        x_p = torch.sigmoid(self.alpha * (x_normed - x_normed.detach()))\n",
    "        return x * x_p + (1 - x_p) * x_normed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义的激活函数\n",
    "class CustomActivation(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.clamp(x, min=1, max=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DINModel(nn.Module):\n",
    "    def __init__(self, uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num, embedding_dim=16, attention_units=32):\n",
    "        \"\"\"初始化DIN模型\"\"\"\n",
    "        super(DINModel, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        # 用户特征嵌入层\n",
    "        self.uid_embedding = nn.Embedding(uid_num, embedding_dim)\n",
    "        self.gender_embedding = nn.Embedding(gender_num, embedding_dim)\n",
    "        self.age_embedding = nn.Embedding(age_num, embedding_dim)\n",
    "        self.job_embedding = nn.Embedding(job_num, embedding_dim)\n",
    "\n",
    "        # 电影特征嵌入层\n",
    "        self.movie_id_embedding = nn.Embedding(mid_num, embedding_dim)\n",
    "        self.movie_categories_embedding = nn.Embedding(movie_category_num, embedding_dim)\n",
    "        self.movie_title_embedding = nn.Embedding(movie_title_num, embedding_dim)\n",
    "\n",
    "        # 历史电影特征嵌入层\n",
    "        self.history_movie_embedding = nn.Embedding(mid_num, embedding_dim)\n",
    "\n",
    "        # 注意力层\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, attention_units),\n",
    "            Dice(attention_units),\n",
    "            nn.Linear(attention_units, attention_units),\n",
    "            Dice(attention_units),\n",
    "            nn.Linear(attention_units, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # 预测层\n",
    "        self.prediction = nn.Sequential(\n",
    "            nn.Linear(embedding_dim*8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            CustomActivation()  # 使用自定义激活函数\n",
    "        )\n",
    "\n",
    "    def forward(self, uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, history_movie_ids):\n",
    "        \"\"\"前向传播\n",
    "        Args:\n",
    "            uid: 用户ID [batch_size] []\n",
    "            user_gender: 用户性别 [batch_size] []\n",
    "            user_age: 用户年龄 [batch_size] []\n",
    "            user_job: 用户职业 [batch_size] []\n",
    "            movie_id: 候选电影ID [batch_size] []\n",
    "            movie_categories: 候选电影类别 [batch_size] [18]\n",
    "            movie_titles: 候选电影标题 [batch_size] [18]\n",
    "            history_movie_ids: 历史交互电影ID [batch_size, hist_len] [2314]\n",
    "        \"\"\"\n",
    "\n",
    "        # 嵌入用户特征\n",
    "        uid_embed = self.uid_embedding(uid)\n",
    "        gender_embed = self.gender_embedding(user_gender)\n",
    "        age_embed = self.age_embedding(user_age)\n",
    "        job_embed = self.job_embedding(user_job)\n",
    "\n",
    "        # 嵌入候选电影特征\n",
    "        movie_id_embed = self.movie_id_embedding(movie_id)\n",
    "        movie_categories_embed = self.movie_categories_embedding(movie_categories)\n",
    "        movie_titles_embed = self.movie_title_embedding(movie_titles)\n",
    "\n",
    "        # 嵌入历史电影ID特征\n",
    "        hist_movie_embed = self.history_movie_embedding(history_movie_ids)\n",
    "\n",
    "        # 注意力机制处理历史交互\n",
    "        attention_input = torch.cat([\n",
    "            movie_id_embed.unsqueeze(1),\n",
    "            hist_movie_embed\n",
    "        ], dim=1)\n",
    "\n",
    "        # 扩展最后一个维度\n",
    "        attention_input_expanded = torch.cat([attention_input, attention_input], dim=-1)\n",
    "\n",
    "        # 调整其维度\n",
    "        batch_size, seq_len, _ = attention_input_expanded.shape\n",
    "        embedding_dim = 16\n",
    "        attention_input_reshaped = attention_input_expanded.view(-1, embedding_dim * 2)\n",
    "        attention_weight = self.attention(attention_input_reshaped)\n",
    "\n",
    "        # 恢复形状\n",
    "        attention_output = attention_weight.view(batch_size, seq_len, 1)\n",
    "\n",
    "        # 调整 attention_output 的维度，使其与 hist_movie_embed 匹配\n",
    "        attention_output = attention_output[:, 1:, :]\n",
    "        hist_attention = torch.sum(attention_output * hist_movie_embed, dim=1)\n",
    "\n",
    "        # 这里的特征维度一定要对齐\n",
    "        movie_categories_embed_mean = torch.mean(movie_categories_embed, dim=1)\n",
    "        movie_titles_embed_mean = torch.mean(movie_titles_embed, dim=1)\n",
    "\n",
    "\n",
    "        # print(\"uid_embed维度:\", uid_embed.size())\n",
    "        # print(\"gender_embed维度:\", gender_embed.size())\n",
    "        # print(\"age_embed维度:\", age_embed.size())\n",
    "        # print(\"job_embed维度:\", job_embed.size())\n",
    "        # print(\"movie_id_embed维度:\", movie_id_embed.size())\n",
    "        # print(\"movie_categories_embed_mean维度:\", movie_categories_embed_mean.size())\n",
    "        # print(\"movie_titles_embed_mean维度:\", movie_titles_embed_mean.size())\n",
    "        # print(\"hist_attention:\", hist_attention.size())\n",
    "        concat_features = torch.cat([\n",
    "            uid_embed,  # [32, 16]\n",
    "            gender_embed, # [32, 16]\n",
    "            age_embed, # [32, 16]\n",
    "            job_embed, # [32, 16]\n",
    "            movie_id_embed,  # [32, 16]\n",
    "            movie_categories_embed_mean,  # [32, 16]\n",
    "            movie_titles_embed_mean, # [32, 16]\n",
    "            hist_attention # [32, 16]\n",
    "        ], dim=1)  #【32, 128]\n",
    "\n",
    "        # 输出预测分数\n",
    "        return self.prediction(concat_features) # [32, 1] 32为一个批次，其中每个值都代表一个预测分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        uid = torch.tensor(self.features[idx][0])\n",
    "        movie_id = torch.tensor(self.features[idx][1])\n",
    "        user_gender = torch.tensor(self.features[idx][2])\n",
    "        user_age = torch.tensor(self.features[idx][3])\n",
    "        user_job = torch.tensor(self.features[idx][4])\n",
    "        movie_titles = torch.tensor(self.features[idx][6])\n",
    "        movie_categories = torch.tensor(self.features[idx][7])\n",
    "        history_movie_ids = torch.tensor(self.features[idx][8])\n",
    "\n",
    "        targets = torch.tensor(self.targets[idx]).float()\n",
    "        return uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, history_movie_ids, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"使用设备{device}\")\n",
    "\n",
    "class RankModel:\n",
    "    def __init__(self, uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num):\n",
    "        \"\"\"初始化DIN排序模型\"\"\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = DINModel(uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num).to(self.device)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters())\n",
    "        self.criterion = nn.MSELoss() \n",
    "\n",
    "    def train(self, train_loader, num_epochs=1):\n",
    "        \"\"\"训练模型\n",
    "        Args:\n",
    "            train_features: 训练集特征\n",
    "            train_targets: 训练集标签\n",
    "        \"\"\"\n",
    "        print(\"开始训练DIN排序模型...\")\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            for batch_i, (uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, history_movie_ids, ratings) in enumerate(train_loader):\n",
    "                self.optimizer.zero_grad()\n",
    "                uid = uid.to(device) # [32] 32表示batch_size\n",
    "                user_gender = user_gender.to(device) # [32] \n",
    "                user_age = user_age.to(device) # [32]\n",
    "                user_job = user_job.to(device) # [32]\n",
    "                movie_id = movie_id.to(device) # [32]\n",
    "                movie_categories = movie_categories.to(device) # [32, 18] 32表示batch_size，18表示电影的类型\n",
    "                movie_titles = movie_titles.to(device) # [32, 15] 32表示batch_size, 15表示每个电影的长度\n",
    "                history_movie_ids = history_movie_ids.to(device).long() # [32, 2314] 但是这里现在是[32]有问题 \n",
    "                ratings = ratings.float().to(device) # [32]\n",
    "\n",
    "                # 前向传播\n",
    "                outputs = self.model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, history_movie_ids)\n",
    "                loss = self.criterion(outputs, ratings)\n",
    "                # 反向传播和优化\n",
    "                loss.backward()\n",
    "\n",
    "                # # 计算梯度范数（检查是否有出现梯度爆炸）\n",
    "                # total_norm = 0\n",
    "                # for p in self.model.parameters():\n",
    "                #     param_norm = p.grad.data.norm(2)\n",
    "                #     total_norm += param_norm.item() ** 2\n",
    "                # total_norm = total_norm ** (1. / 2)\n",
    "                # print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{batch_i + 1}/{len(train_loader)}], Gradient Norm: {total_norm:.4f}\")\n",
    "\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "\n",
    "                self.optimizer.step()\n",
    "                if (batch_i + 1) % 100 == 0:\n",
    "                    print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{batch_i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "        print(\"训练完成！\")\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        \"\"\"评估模型\n",
    "        Args:\n",
    "            test_loader: 测试集的DataLoader\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        all_predictions = []\n",
    "        all_ratings = []\n",
    "        with torch.no_grad():\n",
    "            for batch_i, (uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, history_movie_ids, ratings) in enumerate(test_loader):\n",
    "                uid = uid.to(self.device)\n",
    "                user_gender = user_gender.to(self.device)\n",
    "                user_age = user_age.to(self.device)\n",
    "                user_job = user_job.to(self.device)\n",
    "                movie_id = movie_id.to(self.device)\n",
    "                movie_categories = movie_categories.to(self.device)\n",
    "                movie_titles = movie_titles.to(self.device)\n",
    "                ratings = ratings.to(self.device)\n",
    "                history_movie_ids=history_movie_ids.to(self.device)\n",
    "                predictions = self.model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles)\n",
    "                all_predictions.extend(predictions.cpu().numpy().flatten())\n",
    "                all_ratings.extend(ratings.cpu().numpy().flatten())\n",
    "\n",
    "        mse = mean_squared_error(all_ratings, all_predictions)\n",
    "        mae = mean_absolute_error(all_ratings, all_predictions)\n",
    "        print(f\"测试集MSE: {mse:.4f}\")\n",
    "        print(f\"测试集MAE: {mae:.4f}\")\n",
    "\n",
    "    def predict(self, features: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"预测评分\n",
    "        Args:\n",
    "            features: 待预测特征\n",
    "        Returns:\n",
    "            预测的评分\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            uid = torch.tensor(features[:, 0].to(self.device))\n",
    "            user_gender = torch.tensor(features[:, 2].to(self.device))\n",
    "            user_age = torch.tensor(features[:, 3].to(self.device))\n",
    "            user_job = torch.tensor(features[:, 4].to(self.device))\n",
    "            movie_id = torch.tensor(features[:, 1].to(self.device))\n",
    "            movie_categories = torch.tensor(features[:, 7].to(self.device))\n",
    "            movie_titles = torch.tensor(features[:, 6].to(self.device))\n",
    "            history_movie_ids = torch.tensor(features[:, 8].to(self.device))\n",
    "\n",
    "            predictions = self.model(uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, history_movie_ids)\n",
    "            return predictions.cpu().numpy()\n",
    "\n",
    "    def get_recommendations(self, user_features: np.ndarray, recall_movie_features: np.ndarray, top_k: int = 10) -> List[Tuple[int, float]]:\n",
    "        \"\"\"获取推荐电影列表\n",
    "        Args:\n",
    "            user_features: 用户特征\n",
    "            recall_movie_features: 召回的候选电影特征\n",
    "            top_k: 推荐电影数量\n",
    "        Returns:\n",
    "            推荐电影列表，每个元素为(电影ID, 预测评分)\n",
    "        \"\"\"\n",
    "        predictions = self.predict(recall_movie_features)\n",
    "        movie_scores = list(enumerate(predictions))\n",
    "        movie_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return movie_scores[:top_k]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_targets, test_features, test_targets=pickle.load(open('./data/split_dataset.p', 'rb'))\n",
    "title2int, title_count, title_set, genres2int, genres_map, features_pd, targets_pd, features, targets_values, ratings_df, users_df, movies_df, data = pickle.load(open('./data/preprocess.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4835, 130, 3852, 2242, 1296, 4153, 3512, 3512...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4809, 4472, 2242, 3869, 1291, 3512, 3512, 351...</td>\n",
       "      <td>[11, 15, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4394, 1320, 1007, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[1951, 4696, 3512, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[722, 932, 973, 3512, 3512, 3512, 3512, 3512, ...</td>\n",
       "      <td>[11, 15, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  gender  age  occupation zip_code  \\\n",
       "0        1      1193       5       1    0          10    48067   \n",
       "1        1       661       3       1    0          10    48067   \n",
       "2        1       914       3       1    0          10    48067   \n",
       "3        1      3408       4       1    0          10    48067   \n",
       "4        1      2355       5       1    0          10    48067   \n",
       "\n",
       "                                               title  \\\n",
       "0  [4835, 130, 3852, 2242, 1296, 4153, 3512, 3512...   \n",
       "1  [4809, 4472, 2242, 3869, 1291, 3512, 3512, 351...   \n",
       "2  [4394, 1320, 1007, 3512, 3512, 3512, 3512, 351...   \n",
       "3  [1951, 4696, 3512, 3512, 3512, 3512, 3512, 351...   \n",
       "4  [722, 932, 973, 3512, 3512, 3512, 3512, 3512, ...   \n",
       "\n",
       "                                              genres  \n",
       "0  [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "1  [11, 15, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...  \n",
       "2  [0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "3  [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...  \n",
       "4  [11, 15, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie_ids = data.groupby('user_id')['movie_id'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在data后增加一列，用来记录用户的历史观看的电影ID\n",
    "new_data = pd.merge(data, user_movie_ids, on='user_id', how='left')\n",
    "\n",
    "# 修改列名\n",
    "new_data=new_data.rename(columns={'movie_id_y':'history_movie_ids', 'movie_id_x': 'movie_id'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>history_movie_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4835, 130, 3852, 2242, 1296, 4153, 3512, 3512...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4809, 4472, 2242, 3869, 1291, 3512, 3512, 351...</td>\n",
       "      <td>[11, 15, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[4394, 1320, 1007, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[1951, 4696, 3512, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>[722, 932, 973, 3512, 3512, 3512, 3512, 3512, ...</td>\n",
       "      <td>[11, 15, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "      <td>[1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "      <td>[5025, 378, 4350, 3512, 3512, 3512, 3512, 3512...</td>\n",
       "      <td>[6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "      <td>[3690, 1768, 4315, 3512, 3512, 3512, 3512, 351...</td>\n",
       "      <td>[4, 5, 12, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,...</td>\n",
       "      <td>[573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "      <td>[1050, 390, 2242, 314, 3512, 3512, 3512, 3512,...</td>\n",
       "      <td>[6, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "      <td>[2220, 766, 3512, 3512, 3512, 3512, 3512, 3512...</td>\n",
       "      <td>[4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...</td>\n",
       "      <td>[573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "      <td>[2950, 2242, 585, 3512, 3512, 3512, 3512, 3512...</td>\n",
       "      <td>[15, 4, 3, 18, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...</td>\n",
       "      <td>[573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  movie_id  rating  gender  age  occupation zip_code  \\\n",
       "0              1      1193       5       1    0          10    48067   \n",
       "1              1       661       3       1    0          10    48067   \n",
       "2              1       914       3       1    0          10    48067   \n",
       "3              1      3408       4       1    0          10    48067   \n",
       "4              1      2355       5       1    0          10    48067   \n",
       "...          ...       ...     ...     ...  ...         ...      ...   \n",
       "1000204     6040      1091       1       0    6           6    11106   \n",
       "1000205     6040      1094       5       0    6           6    11106   \n",
       "1000206     6040       562       5       0    6           6    11106   \n",
       "1000207     6040      1096       4       0    6           6    11106   \n",
       "1000208     6040      1097       4       0    6           6    11106   \n",
       "\n",
       "                                                     title  \\\n",
       "0        [4835, 130, 3852, 2242, 1296, 4153, 3512, 3512...   \n",
       "1        [4809, 4472, 2242, 3869, 1291, 3512, 3512, 351...   \n",
       "2        [4394, 1320, 1007, 3512, 3512, 3512, 3512, 351...   \n",
       "3        [1951, 4696, 3512, 3512, 3512, 3512, 3512, 351...   \n",
       "4        [722, 932, 973, 3512, 3512, 3512, 3512, 3512, ...   \n",
       "...                                                    ...   \n",
       "1000204  [5025, 378, 4350, 3512, 3512, 3512, 3512, 3512...   \n",
       "1000205  [3690, 1768, 4315, 3512, 3512, 3512, 3512, 351...   \n",
       "1000206  [1050, 390, 2242, 314, 3512, 3512, 3512, 3512,...   \n",
       "1000207  [2220, 766, 3512, 3512, 3512, 3512, 3512, 3512...   \n",
       "1000208  [2950, 2242, 585, 3512, 3512, 3512, 3512, 3512...   \n",
       "\n",
       "                                                    genres  \\\n",
       "0        [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "1        [11, 15, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...   \n",
       "2        [0, 5, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "3        [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "4        [11, 15, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...   \n",
       "...                                                    ...   \n",
       "1000204  [6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "1000205  [4, 5, 12, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,...   \n",
       "1000206  [6, 4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "1000207  [4, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, ...   \n",
       "1000208  [15, 4, 3, 18, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7...   \n",
       "\n",
       "                                         history_movie_ids  \n",
       "0        [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  \n",
       "1        [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  \n",
       "2        [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  \n",
       "3        [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  \n",
       "4        [1193, 661, 914, 3408, 2355, 1197, 1287, 2804,...  \n",
       "...                                                    ...  \n",
       "1000204  [573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...  \n",
       "1000205  [573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...  \n",
       "1000206  [573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...  \n",
       "1000207  [573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...  \n",
       "1000208  [573, 589, 1, 2068, 592, 593, 3016, 3017, 2070...  \n",
       "\n",
       "[1000209 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最长的历史电影ID数量为: 2314\n",
      "这些数组仍未被填充: []\n"
     ]
    }
   ],
   "source": [
    "# 填充new_data的history_movie_ids列\n",
    "# 1. 找到history_movie_ids最长是多少\n",
    "max_hist_len = max([len(arr) for arr in new_data['history_movie_ids']])\n",
    "print(\"最长的历史电影ID数量为:\", max_hist_len)\n",
    "\n",
    "# 2. 对history_movie_ids进行填充操作\n",
    "def pad_array(arr):\n",
    "    arr_len = len(arr)\n",
    "    if arr_len < max_hist_len:\n",
    "        # 选择数组中的第一个元素进行填充（你也可以按需选择其他元素）\n",
    "        fill_element = arr[0]\n",
    "        padding = [fill_element] * (max_hist_len - arr_len)\n",
    "        arr = arr + padding\n",
    "    return arr\n",
    "\n",
    "new_data['history_movie_ids'] = new_data['history_movie_ids'].apply(pad_array)\n",
    "\n",
    "# 3. 检查填充后的结果\n",
    "wrong_ids=[len(arr) for arr in new_data['history_movie_ids'] if len(arr)!=max_hist_len]\n",
    "print(\"这些数组仍未被填充:\", wrong_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始划分训练集和测试集...\n",
      "训练集大小: 800167\n",
      "测试集大小: 200042\n"
     ]
    }
   ],
   "source": [
    "# 从data中划分训练集和测试集\n",
    "print(\"开始划分训练集和测试集...\")\n",
    "\n",
    "# 将数据转换为numpy数组\n",
    "features = np.array(new_data[['user_id', 'movie_id', 'gender', 'age', 'occupation', 'zip_code', 'title', 'genres', 'history_movie_ids']].values)\n",
    "targets = np.array(new_data['rating'].values)\n",
    "\n",
    "\n",
    "# 使用train_test_split划分训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features, test_features, train_targets, test_targets = train_test_split(\n",
    "    features, targets, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {len(train_features)}\")\n",
    "print(f\"测试集大小: {len(test_features)}\")\n",
    "\n",
    "train_dataset=MovieDataset(train_features, train_targets)\n",
    "test_dataset=MovieDataset(test_features, test_targets)\n",
    "train_loader=DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader=DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练模型...\n",
      "开始训练DIN排序模型...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bytedance/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100/25006], Loss: 2.4688\n",
      "Epoch [1/1], Step [200/25006], Loss: 2.7500\n",
      "Epoch [1/1], Step [300/25006], Loss: 4.2597\n",
      "Epoch [1/1], Step [400/25006], Loss: 2.2457\n",
      "Epoch [1/1], Step [500/25006], Loss: 3.1473\n",
      "Epoch [1/1], Step [600/25006], Loss: 2.9061\n",
      "Epoch [1/1], Step [700/25006], Loss: 2.7488\n",
      "Epoch [1/1], Step [800/25006], Loss: 3.6204\n",
      "Epoch [1/1], Step [900/25006], Loss: 3.0548\n",
      "Epoch [1/1], Step [1000/25006], Loss: 4.0913\n",
      "Epoch [1/1], Step [1100/25006], Loss: 2.3674\n",
      "Epoch [1/1], Step [1200/25006], Loss: 2.0326\n",
      "Epoch [1/1], Step [1300/25006], Loss: 3.2326\n",
      "Epoch [1/1], Step [1400/25006], Loss: 2.2234\n",
      "Epoch [1/1], Step [1500/25006], Loss: 2.7326\n",
      "Epoch [1/1], Step [1600/25006], Loss: 2.2675\n",
      "Epoch [1/1], Step [1700/25006], Loss: 3.9018\n",
      "Epoch [1/1], Step [1800/25006], Loss: 2.2874\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m开始训练模型...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mrank_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 评估模型\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m开始评估模型...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m, in \u001b[0;36mRankModel.train\u001b[0;34m(self, train_loader, num_epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_i, (uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, history_movie_ids, ratings) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     29\u001b[0m         uid \u001b[38;5;241m=\u001b[39m uid\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# [32] 32表示batch_size\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    714\u001b[0m ):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[5], line 19\u001b[0m, in \u001b[0;36mMovieDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m movie_titles \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures[idx][\u001b[38;5;241m6\u001b[39m])\n\u001b[1;32m     18\u001b[0m movie_categories \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures[idx][\u001b[38;5;241m7\u001b[39m])\n\u001b[0;32m---> 19\u001b[0m history_movie_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[idx])\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m uid, movie_id, user_gender, user_age, user_job, movie_titles, movie_categories, history_movie_ids, targets\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "embed_dim = 32\n",
    "# 用户 ID 个数\n",
    "uid_num = max(features.take(0, 1)) + 1\n",
    "# 性别个数\n",
    "gender_num = max(features.take(2, 1)) + 1\n",
    "# 年龄类别个数\n",
    "age_num = max(features.take(3, 1)) + 1\n",
    "# 职业个数\n",
    "job_num = max(features.take(4, 1)) + 1\n",
    "\n",
    "# 电影 ID 个数\n",
    "mid_num = max(features.take(1, 1)) + 1\n",
    "# 电影类型个数\n",
    "movie_category_num = max(genres2int.values()) + 1\n",
    "# 电影名单词个数\n",
    "movie_title_num = len(title_set)\n",
    "\n",
    "# 初始化排序模型\n",
    "rank_model = RankModel(uid_num, gender_num, age_num, job_num, mid_num, movie_category_num, movie_title_num)\n",
    "\n",
    "# 训练模型\n",
    "print(\"开始训练模型...\")\n",
    "rank_model.train(train_loader)\n",
    "\n",
    "# 评估模型\n",
    "print(\"开始评估模型...\")\n",
    "rank_model.evaluate(test_features, test_targets)\n",
    "\n",
    "# 保存模型\n",
    "save_dir = os.path.join(os.getcwd(), \"model_save\")\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "# 获取当前日期作为模型文件名的一部分\n",
    "from datetime import datetime\n",
    "today = datetime.today()\n",
    "formatted_date = today.strftime('%Y%m%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
